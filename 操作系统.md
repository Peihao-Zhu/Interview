[TOC]



# 1基础

## 1.1 ★★★  进程与线程的本质区别、以及各自的使用场景。

进程与线程的本质区别可以从拥有资源、调度、系统开销、通信等方面考虑

- 拥有资源

  进程是系统资源分配的基本单位，但线程不拥有系统资源，只拥有一点资源（如程序计数器，一组寄存器和栈）。一个进程中的多个线程可以共享该进程中的资源，如：内存、IO、CPU等。

- 调度

  线程是CPU调度的基本单位，同一个进程中的线程切换不会引起进程的切换。

- 系统开销

  创建或撤销进程时，系统都要为他分配或回收资源，如：内存空间、IO设备等，所付出的开销远远大于创建或撤销线程的开销。同样在进程切换时，涉及到当前进程CPU环境的保存以及新进程CPU环境的设置，而线程切换只需要设置和保存少量寄存器内容，并不涉及到存储器管理方面的操作。

- 通信

  线程间的通信可以共享同一进程中的数据；但是进程之间的通信要通过IPC。、

- 安全性

  多线程程序只要有一个线程崩溃，进程就崩溃了（因为共用一个地址空间），但多进程程序中只要有一个进程崩溃并不会对其他进程造成影响，因为进程有自己的独立地址空间，更加健壮。



使用场景：

线程：对于慢IO，追求速度

进程：安全稳定



**同一进程中的线程共享哪些数据？**

- 进程代码段（地址空间）
- 进程的公有数据（全局变量，静态变量）
- 进程打开的文件描述符
- 进程ID和进程组ID
- 信号处理器/信号处理函数：对收到的信号的处理方式

**线程独占哪些资源**

- 线程ID
- 寄存器
- 线程自身的栈（堆是线程共享的）
- 错误返回码：线程可能会返回不同的错误返回码，一个线程的错误返回码不应该被其他线程修改

## 1.2 ★☆☆ 进程状态。

![img](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806151033.png)

注意：只有就绪态和运行态可以相互转换；阻塞状态是缺少需要的资源(I/O),不包括CPU资源，如果缺少CPU资源，会进入就绪态。

## 1.3 ★★★ 进程调度算法的特点以及使用场景。

##### （1）批处理系统

没有太多用户操作，调度算法的目标是保证吞吐量和周转时间

a. 先来先服务FCFS

非抢占式调度算法，对短作业不利，对IO密集型进程不利。

b. 短作业优先SJF

非抢占式调度算法，吞吐量高，长作业可能会饿死

c. 最短剩余时间优先SRTF

短作业优先的抢占式版本，按剩余运行时间进行调度，如果新的作业剩余时间比当前作业短，就挂起当前进程，运行新的进程。

 

##### （2）交互式系统

有大量的用户交互操作，目标是快速响应

a. 时间片轮转

把就绪进程按照FCFS排成一个队列，每次把CPU时间分配给队首进程，当时间片用完时，计时器发出时钟中断，调度程序便停止该进程，并送往就绪队列队尾。为短进程提供好的响应时间。

b. 优先级调度

为每个进程分配优先级，为了防止低优先级进程永远等不到调度，随着时间推移增加等待进程的优先级。

c. 多级反馈队列

某些进程需要重复执行很多次时间片轮转，所以设置多级队列，每个队列的时间片大小不同（最上面时间片最小）。每个队列的优先级也不同，最上面的优先级最高。

![img](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806151605.png) 

 

##### （3）实时系统

要求一个请求在一定时间内得到响应。分为硬实时和软实时（可以容忍一定的超时）。

根据调度方式可以分为：抢占式，非抢占式

详细例子可以参考

https://blog.csdn.net/qq_34902437/article/details/82898232

a. 最早截止时间优先EDF

作业截止时间越早，先执行。下面例子中二三行是简单的优先级调度（都是抢占式的），可以发现都不符合实时系统，最后一行的EDF，可以达成目标。其实质就是每一个作业进来，就和当前作业比较截止时间离现在更近，如果新来的进程更近，当前进程挂起。

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806151737.png)

b. 最低松弛度优先LLF(Least Laxity First)

松弛度=必须完成的时间-本身运行时间-当前时间。松弛度越低，表示越紧急，优先级越高。

先举一个下例子。比如此时时间轴为 0ms，任务 A 和 B 同时到达，需要确定先执行哪个任务。

 

任务 A 需要在 200ms 这个时刻（或之前）完成，而 A 本身要运行 100ms。所以 A 的松弛度就是 200 - 100 - 0 = 100ms。

此时还有一个任务 B ，必须在 400ms 时刻（或者之前）完成，本身需要运行 150ms，所以松弛度为 400 - 150 - 0 = 250

所以先运行任务A。



##### 什么叫优先级反转？如何解决

高优先级的进程等待被一个低优先级进程占用的资源时，就会出现优先级反转，即优先级较低的进程比优先级较高的进程先执行。

解决方法：

- 优先级天花板(priority ceiling)：当任务申请某资源时，把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天花板。简单易行。
- 优先级继承(priority inheritance)：当任务A申请共享资源S时，如果S正在被任务C使用，通过比较任务C与自身的优先级，如发现任务C的优先级小于自身的优先级，则将任务C的优先级提升到自身的优先级，任务C释放资源S后，再恢复任务C的原优先级。

## 1.4 ★☆☆ 线程实现的方式。	

https://blog.csdn.net/gatieme/article/details/51892437

https://www.cnblogs.com/baoendemao/p/3804677.html



**首先应该明白，进程的调度、创建实质上都是操作系统实现的，所以说进程的实现只能由操作系统内核实现，而不再用户态实现。但是线程不一样，线程的管理者可以是用户也可以是操作系统本身，所以线程的实现分为用户级线程和内核级线程。**



用户级线程：由应用程序支持的线程实现，内核意识不到用户级线程的实现

内核级线程：内核支持线程

##### （1）用户级线程

有关线程管理的所有工作由应用程序完成，内核意识不到线程的存在。应用程序可以通过线程库设计多线程程序。用户线程仅存在于用户空间，线程创建、撤销、线程之间的同步和通信功能都无须利用系统调用实现。对操作系统不可见，无法被调度到处理器内核，每个线程并不具有自身的线程上下文，同一时刻一个进程只能由一个线程在运行。（我觉得是这样理解，因为操作系统内核时感知不到用户线程的存在，所以会根据一个进程分配一个内核线程，然后进程中的多个线程每次只能有一个线程被内核线程关联运行。）

![用户级线程的实现方式,](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806152113.jpeg) 

库调度器从进程中选择一个线程，将该线程与内核允许的线程关联。内核线程将被操作系统调度器指派到处理器内核。

**优点：**

- 可以在不支持线程的操作系统中实现
- 创建和撤销、切换线程的代价，还有现场管理的代价要比内核线程小的多。
- 不需要上下文切换
- 线程的调度不需要内核直接参与。 

##### （2）内核级线程

内核线程的创建和销毁都是由操作系统负责，通过系统调用完成。无论用户进程的线程还是系统进程的线程都依靠内核完成。应用程序没有线程管理的代码，只有到内核线程的接口。

![内核级线程的实现方式](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806152123.jpeg)

内核线程驻留在内核空间，每个用户线程被映射到一个内核线程，用户线程在生命期内都和该内核线程绑定，一旦用户线程重置，两个线程都将离开系统。

内核空间为每一个内核设置了TCB（线程控制块），根据TCB感知线程的存在。

进程的每个线程在资源可用时都可以被只派到处理器内核，操作系统为每个线程创建上下文，所以同一时刻一个进程可以有多线程并行执行。

 

**优点：**

- 用户线程具有上下文，所以当一个线程被阻塞，能够切换同一进程中的其他线程继续执行
- 在多处理系统中，内核能并行执行一个进程中的多个线程
- 信号时发给进程的不是发给线程的，线程通过注册各自感兴趣的信号来处理



##### 用户级线程和内核级线程的区别

- 用户级线程执行系统调用会导致其所属的进程被中断，而内核级线程只会导致该线程被中断。
- 在只有用户级线程的系统中，CPU的调度是以进程为单位的
- 用户级线程的程序实体运行在用户态下，而内核支持线程的程序实体可以运行在任何状态下。

## 1.5 ★★☆ 协程的作用。

https://blog.csdn.net/chengqiuming/article/details/80573288?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase

​		协程是一种**用户态的轻量级线程**，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

协程既不是进程也不是线程，仅仅是一个特殊的函数，一个线程可以包含多个协程，但是多个协程的运行必须是串行的，无论有多少个cpu（核），一个协程运行时，其他协程就会挂起。

 

![img](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806163618.png)

协程的切换仅仅是CPU上下文切换，而线程的切换还包括缓存等，避免系统调用，所以协程切换效率更高。

 

适用于I/O阻塞（因为无论IO速度多快，都比不上CPU速度，所以如果一个程序在执行IO，此时大的CPU都是空闲的），当一个线程有很多I/O要处理时，可以用多个协程，前一个协程I/O阻塞时切换到下一个协程（高并发）。

但是因为协程不能利用多核，所以对于IO密集型程序，可以使用“多进程+协程”，多进程是用来并行执行。

#### 协程和线程比较？

- 一个线程可以拥有多个协程，一个进程也可以拥有多个协程
- 进程和线程都是同步机制，协程是异步机制
- 协程能保留上一次调用时的状态。

 

## 1.6 ★★☆ 常见进程同步问题。

https://www.cnblogs.com/pluslius/p/10079885.html

<u>进程的同步是目的，要实现进程的同步要通过进程之间的通信来实现。</u>

#### 管程Monitor

管程将共享变量和对共享变量的操作封装起来，并设计一定接口，这样只能通过管程提供的接口来访问管程中的资源。进程只能互斥的使用管程（由编译器负责保证）；在管程中设置条件变量及等待/唤醒操作解决同步问题：让一个进程或线程等待（此时要释放管程的使用权），也可以唤醒一个在等待条件变量的进程或线程。

------------------------------------------------------------------------------------------------------------------------

针对上面的描述有这么一个场景，一个进入管程的进程执行等待操作后，会释放管程，当之后进入管程的进程又执行了唤醒操作，唤醒刚才等待的进程（P唤醒Q），此时会有两个进程都在活动状态

解决方法：

1. P等待Q先执行，P在**紧急等待队列**中等待（HOARE管程）
2. Q等待P先执行（MESA管程）
3. 规定唤醒操作为管程中最后一个可执行的操作

**HOARE管程：**

管程的入口处设置**入口等待队列**，还有一个上面讲到的**紧急等待队列**，优先级后者高。

wait操作：执行wait操作的进程进入条件变量链的末尾，唤醒紧急等待队列或入口队列的进程

signal操作：唤醒条件变量链中的进程，自己进入紧急等待队列。

**MESA管程**：

MESA管程将signal-->notify，没有额外的进程切换

notify操作：条件队列头的进程在合适且处理器可用时恢复执行；由于不能保证在它之前没有其他进程进入管程，所以进入之前用while循环检查条件是否合适。

#### a. 生产者-消费者问题

 注意：生产者生产时，都需要先判断empty信号量，在进行缓冲区的加锁。如果先加锁了，却发现empty已经为0，此时生产者被阻塞，但是因为缓冲区的锁没有被释放，所以消费者也不能进行消费，两边会一直等待下去。

```java
#define N 100
typedef int semaphore;
semaphore mutex = 1; //缓冲区是临界资源，需要互斥访问
semaphore empty = N; //缓冲区中空的数量，用于消费者消费的时候判断
semaphore full = 0;  //缓冲区占有的数量，用于生产者生产时候的判断

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}

```



#### b. 哲学家进餐问题

 https://blog.csdn.net/qq_28602957/article/details/53538329

这里介绍了好几种方法，觉得其中两种比较好，详细介绍一下

**方法一**

对于N个哲学家，最多只允许N-1个哲学家同时去拿左筷子，这样肯定能保证至少一位哲学家进餐，进餐完后释放两个筷子，供别人使用。

```java
semaphore chopsticks[5]=[1,1,1,1,1]; //临界区，一个筷子只能被一个人拿起来，互斥访问
semaphore capacity=N-1 //最多只允许N-1个哲学家进来拿筷子
void philosopher(int i){
	while(True){
		think();
		//允许N-1个人来拿筷子
		down(capacity);
		down(chopsticks[i]);// 先拿左筷子
		down(chopsticks[(i+1)%N]);//再拿右筷子
		eat();
		up(chopsticks[(i+1)%N]);
		up(chopsticks[i]);
		up(capacity);
		think();
	}
}
```

**方法二**

仅当哲学家的左右边筷子都拿起时才允许进餐，这时会用到AND信号量集。

信号量只能解决单个资源的互斥，AND信号量集能解决对多个资源的互斥访问。Swait（Simultaneous Wait），Ssignal（Simultaneous Signal）

```java
semaphore chopsticks[5]=[1,1,1,1,1]; //临界区，一个筷子只能被一个人拿起来，互斥访问
void philosopher(int i){
	while(True){
		think();
		Swait(chopsticks[i],chopsticks[(i+1)%N]);// 同时拿左筷子和右筷子
		eat();
		Ssignal(chopsticks[i],chopsticks[(i+1)%N]);
		think();
	}
}
```

或者也可以利用信号量的保护机制实现，通过mutex对取左右两个筷子进行保护，防止死锁

```java
semaphore chopsticks[5]=[1,1,1,1,1]; //临界区，一个筷子只能被一个人拿起来，互斥访问
semaphore mutex=1;
void philosopher(int i){
	while(True){
		think();
		down(mutex);
    down(chopsticks[i]);
    down(chopsticks[(i+1)%N]);
    //为什么这里就可以恢复mutex信号量，而不是在最后？
    //当然可以放在最后，但是放在前面的话，执行的效率更高了，mutex的作用只是为了保证能安全的拿左右两个筷子。
    up(mutex);			
		eat();
		up(chopsticks[i]);
    up(chopsticks[(i+1)%N]);
		think();
	}
}
```



#### c. 读者-写者问题

有读者和写者两个并发进程，共享一个文件。要求：

- 允许多个读进程对文件进行读操作
- 只允许一个写进程写信息
- 当任意写进程在写信息之前不允许其他读进程或者写进程进入
- 执行写进程之前，需要让已有的读写进程都退出。

###### 读者优先算法

根据下面代码可以看出，只要有一个读进程，写进程就不能运行，所以读者有更高的优先级，写者很可能会饿死

```java
typedef int semaphore;
int count = 0;		//count是记录读进程的数量
semaphore count_mutex = 1;//对count的加减操作应该是互斥的
semaphore data_mutex = 1; //读进程和写进程互斥


void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex); //如果已经没有读进程了，则对数据解锁，可以允许写进程进入。
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}

```

###### 写者优先算法

```java
typedef int semaphore;
int count = 0;		//count是记录读进程的数量
semaphore count_mutex = 1;//对count的加减操作应该是互斥的
semaphore data_mutex = 1; //读进程和写进程互斥
semaphore w=1;    //当有写进程的时候不允许读进程进入

void reader() {
    while(TRUE) {
      	down(w);
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
      	up(w);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex); //如果已经没有读进程了，则对数据解锁，可以允许写进程进入。
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
      	down(w);
        down(&data_mutex);
        write();
        up(&data_mutex);
      	up(w);
    }
}
```



**临界区的概念？**

各个进程对临界资源（互斥资源/共享资源，一次只能给一个进程使用）进行操作的程序片段

**并发、并行、异步的区别？**

并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序在CPU上运行，宏观上的并发是通过不断的切换实现的；

多线程：并发运行的一段代码。是实现异步的手段

并行（和串行相比）：在多CPU系统中，多个程序无论宏观还是微观上都是同时执行的

异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事

## 1.7 ★★★ 进程通信方法的特点以及使用场景。

https://www.jianshu.com/p/4989c35c9475

 

IPC（InterProcess Communication）的方式：管道、FIFO、消息队列、信号量、共享内存以及socket

 

①　管道（无名管道）

半双工；管道只能在具有公共祖先（父子进程或兄弟进程）的两个进程之间使用

通过调用pipe函数创建，fd[0]是读，fd[1]是写

```java
#include<unistd.h>
int pipe(int fd[2]);      //成功返回0，出错返回-1
```

![108AE5C3-1647-411B-A7A8-07F43A2616F1](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806173509.png)



如果要指定进程之间数据的流向，可以改变父进程的fd和子进程的fd

②　FIFO（有名管道）

可以在不相关的程序之间交换数据

1）FIFO是一种文件类型，创建FIFO类似于创建文件

```java
#include<sys/stat.h>
int mkfifo(const char *path, mode_t mode);

int mkfifoat(int fd, const char *path, mode_t mode);    //成功返回0，失败返回-1
```

2）FIFO用途

- shell命令使用FIFO将数据从一条管道传送到另一条管道。 
- 客户进程-服务器进程应用程序中，FIFO作为汇聚点，在客户进程和服务器进程之间传递数据

客户进程发送请求和接受响应使用不同的FIFO

![07E3F0BC-17A7-4169-83F4-E9FB922BCE28](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806173757.png)

③　消息队列

消息队列是消息的链接表，存储在内核中，有消息队列标志符标识

```java
#include<sys/msg.h>
  //创建一个新的消息队列或打开现有消息队列
int msgget(key_t key, int flag);  
	//将新消息添加到队列尾端
int msgsnd(int msqid, const void *ptr, size_t nbytes, int flag);  
  //从队列中去除消息
ssize_t msgrcv(int msqid, void *ptr, size_t nbytes, long type, int flag);
```

消息队列可以独立于读写进程存在，避免了FIFO同步管道的打开

避免了FIFO同步阻塞问题，不需要进程自己提供同步方法

读进程可以根据**消息类型**有选择的接受消息（根据类型字段）；而不像FIFO只能默认的接受



④　信号量

是一个计数器，为多个进程提供共享数据对象访问。若信号量为正，则进程可以使用该资源，进程将信号量值减一，否则信号量为0，进程进入休眠状态。



⑤　共享内存

允许两个或多个进程共享给定的存储区。是最快的IPC

 

**需要使用信号量来同步进程访问共享内存**

 多个进程可以将同一个文件映射到他们的地址空间从而实现共享内存。



⑥　Socket

进行网络通信，不同机器之间的进程通信。

 

**几种IPC的比较**

1、如果用户传递的信息较少，或者只是为了触发某些行为。**信号**是一种简洁有效的通信方式。但若是进程间要求传递的信息量较大或者存在数据交换的要求，就需要考虑别的通信方式了。

2、无名管道与有名管道的区别在于**单向通信**以及**有关联的进程**。

3、消息队列允许任意进程通过共享队列来进行进程间通信。并由**系统调用**函数来实现消息发送和接收之间的同步。从而使得用户在使用消息缓冲进行通信时不再需要考虑同步问题，使用相对方便。
但是消息队列中信息的复制需要耗费CPU时间，不适宜信息量大或频繁操作的场合。

4、消息队列与管道方式的区别在于，消息队列可以实现**多对多**，并需要在**内存**中实现，而管道可以在**内存或磁盘**上实现。

5、共享内存无须复制，**信息量大**是其最大的优势。但是需要考虑**同步问题**。

## 1.8 ★★★ 死锁必要条件、解决死锁策略，能写出和分析死锁的代码，能说明在数据库管理系统或者 Java 中如何解决死锁。	

https://blog.csdn.net/guaiguaihenguai/article/details/80303835

 

#### 死锁必要条件（肯定包含下面内容）：

1）互斥：一个资源最多只能分配给一个进程

2）占有和等待：已经得到某个资源的进程还可以请求其他新的资源

3）不可抢占：已经被分配给一个进程的资源不能强制性的抢占，只能等该进程释放

4）环路等待：有两个或两个以上进程组成一个回路。

 

#### 解决死锁策略：

1）鸵鸟策略：不采取任何措施，Unix，Linux和Windows采用此策略

2）死锁检测与死锁恢复：

（1） 一个进程一个资源的死锁检测，

圆圈：进程 方框：资源 D->T：进程请求资源T T->E：资源T已经分配给进程E

![img](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806180818.png)

所以存在死锁，通过DFS对搜过的元素做标记，如果又搜到有标记的就表示有环。

 

（2）一个进程需要多个资源

![img](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806180814.png)

E：资源总量

A：资源剩余数量

C：每个进程所拥有的资源数量

R：每个进程请求的资源数量

 

每个进程开始都不标记，

1.寻找一个没被标记的进程Pi，他所请求的资源小于等于A

2.如果找到一个这样的进程，将C矩阵的第i行向量加到A中，标记该进程转回1。

3.如果没有这样的进程，算法终止

 

死锁恢复

1. 抢占恢复：挂起某些进程，抢占他的资源
2. 回滚恢复：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保存进程的历史信息，设置还原点
3. 杀死进程恢复：强制杀死某些进程直到死锁解除为止。

 

3）死锁预防：破坏死锁必要条件中的任意一条，但是互斥是资源的固有属性，无法改变，但可以改变其他条件。

1.破坏”占有和等待“：经常在开始执行时就申请所需要的全部资源

2.破坏“不可抢占”：

3.破坏”环路等待“：给资源同一编号，进程只能按编号顺序请求资源。

4）死锁避免----使用前先判断，只允许不会产生死锁的进程申请资源

（1）先定义安全状态

![img](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806180804.png)

A、B、C表示进程，Has：已经拥有的进程 Max：总共需要的资源数。 从a-->e

的过程可以发现进程都能成功允许，所以称图a是安全状态

 

定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

 

（2）银行家算法

与死锁检测算法很类似

![img](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806180837.png)

左图：已经分配的资源 右图：还没有分配的资源 

E：总资源 P:已分配的资源 A：可用资源

算法：

l 从右图中找小于等于A的进程，如果不存在，系统会发生死锁，状态是不安全的

l 如果找到了，该进程标记为终止，并将右边的已分配资源释放到A中

l 重复以上两步。

只要有一个状态是不安全的，就拒绝进入这个状态。

 

#### 数据库中解决死锁问题

 

一、事务之间对资源访问顺序交替

原因：如果用户1先访问表A（锁住表A）又要访问表B，用户2先访问表B（锁住表B）又要访问表A，此时就会产生死锁。

解决方法：修改程序，如果要锁定两个资源时，按照相同的顺序锁定资源。（都先锁定A再锁定B）

 

二、并发修改同一记录

原因：用户1查询一项记录，随后想要修改，这时用户2修改该记录，用户1获得了共享锁，想升级为排他锁，而用户2有独占锁需要等待用户1释放共享锁，发生死锁。

解决方法：

a.采用乐观锁：使用版本记录机制实现。读取数据是，将其版本号也读出，之后更新数据时，版本号+1，然后比较提交数据的版本和数据库表项中的版本，如果提交的版本大，就更新。（这样容易产生脏数据）

b.采用悲观锁：数据库加锁

三、全表扫描

原因：事务中执行不满足条件的语句，或索引建的不合适就会发生全表扫描。当经常发生全表扫描就会死锁。

 

解决方法：对索引优化。

## 1.9 ★★★ 虚拟内存的作用，分页系统实现虚拟内存原理。

https://blog.csdn.net/zy702432103/article/details/84659748

 

**作用：**让物理内存扩充成更大的逻辑内存。操作系统将内存抽象成地址空间，每个程序拥有自己的地址空间，地址空间被分割成多个块（页）。页被映射到物理内存，不需要映射到连续的物理内存，也不需要所有页都在物理内存中。让程序引用到不再内存中的页，就执行页面调度算法。也就是说不用将程序都掉入内存，通过分页系统实现虚拟内存。

 



![](https://cdn.jsdelivr.net/gh/Peihao-Zhu/blogImage@master/data/20200806180911.png)

**实现分页系统原理：**需要提供硬件支持如页表机制、缺页中断和地址变换机构。

1）页表机制

页号：虚拟地址划分

物理块号：实际地址划分，指向内存中物理块

状态位P：页面是否调入内存

访问字段A：记录本页在一段时间被访问的次数，用于页面置换时参考

修改位M：标识该页再调入内存后是否被修改

 

2）缺页中断

保护CPU环境、分析中断原因、转入缺页中断处理程序、恢复CPU环境等步骤



3）地址变换机制

先检索快表，若找到该页，就修改页表的访问字段，然后利用物理块号和页内偏移量生成物理地址；若没找到，就到内存中查找页表，在对比页表中的状态位P，查看是否调入内存，若没有，就发生缺页中断。

 

在分页系统中进程创建，放入内存，构建页表，在PCB中记录页表存放在内存的首地址即页表长度。

1.运行某进程A时，将A进程PCB中的页表信息写入PTR（页表寄存器）中

2.每执行一条指令时，根据分页计算原理，得到指令的页号X和内部偏移量Y；

3.CPU高速访问PTR找到对应的页表在哪里；

4.查页表数据，得到X实际对应存放的物理块，完成地址映射计算，最终在内存中找到指令。



![EB6F30B5-CAA5-489A-AF68-0A3EB2D4705C](/Users/zhupeihao/Library/Containers/com.tencent.qq/Data/Library/Application Support/QQ/Users/893109628/QQ/Temp.db/EB6F30B5-CAA5-489A-AF68-0A3EB2D4705C.png) 

页表：在内存中。需要访问两次内存(一次用来查询页表用来生成的物理地址，一次根据物理地址访问对应内存块)

快表（Translation Lookaside Buffer）：TLB高速缓存，存放部分页表项（只需要一次缓存一次内存）

## 1.10 ★★★ 页面置换算法的原理，特别是 LRU 的实现原理，最好能手写，再说明它在 Redis 等作为缓存置换算法。	

页面置换的主要目标是使置换频率最低（缺页率最低）

1) OPT最佳置换算法

理论上的算法：被换出的页面将是最长时间不会被访问的，通常可以保证最低的缺页率

2) LRU最近最久未使用

根据过去的页面使用情况，将最近最久未使用的页面换出，使用链表，当页面被访问时将页面移动到链表表头，这样能保证链表表尾的页面是最久未使用的。

3) 最近未使用

![img](file:////private/var/folders/gw/tm5w3wzx75b28wcz_7klvkxm0000gn/T/com.kingsoft.wpsoffice.mac/wps-zhupeihao/ksohtml/wpshgFNzx.jpg) 

为什么是这个置换策略呢？

因为已被修改的脏页面就是最近没有被访问，但是被修改过，由于被修改的原因，所以肯定要换回到硬盘中；而最近访问过的，并且没被修改过的页面没有理由换出去。



4) 先进先出，这算法太鸡肋了

#### 什么是颠簸现象

颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。内存颠簸的解决策略包括：

- 修改页面置换算法；
- 降低同时运行的程序的数量；
- 终止该进程或增加物理内存容量。

#### 手写LRU

```java
public class No1 {

    public static void main(String[] args)  {
        LRU<Integer,Integer> lru=new LRU<>(4);
        for(int i=0;i<10;i++){
            lru.put(i,i);
        }
    }
}

class  LRU<K,V> {

    private Node head;
    private  Node tail;
    //这个hashmap 存储的不是V而是一个链表的Node
    private HashMap<K,Node> map;
    private int maxSize;

    private class Node{
        Node pre;
        Node next;
        K k;
        V v;
        public Node(K k,V v){
            this.k=k;
            this.v=v;
        }
    }
    public  LRU(int maxSize){
        this.maxSize=maxSize;
        this.head=new Node(null,null);
        this.tail=new Node(null,null);
        map=new HashMap<>(maxSize*4/3);
        tail.pre=head;
        head.next=tail;
    }

    public V get(K key){
        //借助hashmap查询O（1）先判断是否存在
        if(!map.containsKey(key)){
            return null;
        }
        Node node=map.get(key);
        unlink(node);
        System.out.println("查询节点： "+node.k);
        insertToHead(node);
        return node.v;
    }
  
    public  void put(K k,V v){
      //如果本身hashmap中已经存在，则修改后插入到表头
        if(map.containsKey(k)){
            Node node=map.get(k);
            unlink(node);
        }
        else{
          Node node=new Node(k,v);
        }
      //插入到hashmap中不要忘了，本来hashmap就存在的话就是修改value的值
        map.put(k,node);
        System.out.println("添加节点： "+node.k);
        insertToHead(node);
        if(map.size()>maxSize){
            Node toBeRemoved=removeFromTail();
            System.out.println("删除节点： "+toBeRemoved.k);
            map.remove(toBeRemoved.k);
        }
    }

    //将原来的节点拿走（放到链表头部）
    private void unlink(Node node){
        Node pre=node.pre;
        Node next=node.next;
        pre.next=next;
        next.pre=pre;

        node.next=null;
        node.pre=null;
    }

    //将节点插到头部
    private void insertToHead(Node node){
        Node next=head.next;
        node.next=next;
        node.pre=head;
        head.next=node;
        next.pre=node;
    }

    //从链表尾部删除节点
    private Node removeFromTail(){
        Node node=tail.pre;
        Node pre=node.pre;
        tail.pre=pre;
        pre.next=tail;

        node.next=null;
        node.pre=null;
        return node;
    }

  
}

```



## 1.11 ★★★ 比较分页与分段的区别。

**分段存储管理**

每个段有自己的名字，都从0开始编址。装入内存时每段赋予各段一个段号。每段占据一块连续的内存，每段大小不等。

地址结构：段号+段内地址

段表：记录每段实际存放的物理地址。包括“内存首地址”和“段长”

![img](file:////private/var/folders/gw/tm5w3wzx75b28wcz_7klvkxm0000gn/T/com.kingsoft.wpsoffice.mac/wps-zhupeihao/ksohtml/wpsjvP9sR.jpg) 

也可以使用TLB来减少内存访问的次数（要看TLB的命中率）。



**分页和分段的区别**

1.需求：分页是出于内存管理需要，用于虚拟内存已获得更大的地址空间，是信息的物理划分单位；分段是用户应用的需要，是一种逻辑划分单位。

2.大小：页的大小时系统固定的，而段的大小是不固定的。分段没有内存碎片，但连续存放段产生外碎片，可以通过内存紧缩来消除，相对分页空间利用率高。

3.逻辑地址：分页是一维的（每个进程的一个页表或多级页表，通过一个逻辑地址就能找到对应的物理地址），分段是二维的（段号+段内偏移）

4.分页对程序员是透明的，但分段需要程序员现实划分

5.碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片。

 

**分段的优点：**

易于实现共享：

- 分段系统中很容易实现共享，只需在每个进程的段表中为共享程序设置一个段表项
- 对共享内容的管理，分段的空间管理更简单，分页需要大量的页面划分和地址管理。

 

**段页式存储管理方式**

将用户程序分成若干段，每个段分成若干页

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181130163627721.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5NzAyNDMyMTAz,size_16,color_FFFFFF,t_70)

![img](file:////private/var/folders/gw/tm5w3wzx75b28wcz_7klvkxm0000gn/T/com.kingsoft.wpsoffice.mac/wps-zhupeihao/ksohtml/wpsbLCuBk.jpg) 



## 1.12 ★★★ 分析静态链接的不足，以及动态链接的特点。

Unix中编译器把源文件转化为目标文件要经过如下步骤：

![img](file:////private/var/folders/gw/tm5w3wzx75b28wcz_7klvkxm0000gn/T/com.kingsoft.wpsoffice.mac/wps-zhupeihao/ksohtml/wpsWwmf5o.png) 

预处理阶段：处理#开头的预处理命令

编译阶段：翻译成汇编文件

汇编阶段；将汇编文件翻译成可重定位目标文件

链接阶段：将可重定位目标文件和printf.o等目标文件合并，得到最终的可执行目标文件。

 

**静态链接**

将一组可重定位目标文件完全链接成一个可执行目标文件，链接器主要完成以下两个任务：

1.符号解析：

2.重定位：

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/47d98583-8bb0-45cc-812d-47eefa0a4a40.jpg)

目标文件

可执行目标文件：可以直接在内存中执行

可重定位目标文件：可与其他可重定位目标文件在链接阶段合并，创建可执行目标文件

共享目标文件：**一种特殊的可重定位目标文件**，可以在运行时被动态加载进内存并链接。

 

**动态链接**

静态链接的不足：

- 当静态库更新时整个程序都要重新进行链接
- 对于printf这种标准库函数，如果每个程序都要代码，会对内存有极大的浪费。

 

共享库是为了解决静态库而设计的，所以在Linux中用.so后缀，Windows中被称为DLL，具有以下特点

-  在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，他不会被复制到引用他的可执行文件中。
- 在内存中，一个共享库的.text（已编译的机器代码）的一个副本可以被不同的正在运行的进程共享。

也就是说DLL文件和EXE文件独立，更换DLL文件不会对EXE文件造成影响，极大的提高了可维护性和扩展性

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/76dc7769-1aac-4888-9bea-064f1caa8e77.jpg)

## 1.13 ★★★线程同步有哪些方式？

为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。

- **互斥量** Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源；
- **信号量** Semaphore：信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了**最大资源计数**和**当前可用资源计数**，每增加一个线程对共享资源的访问，当前可用资源计数就减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过```ReleaseSemaphore```函数将当前可用资源数加1。如果信号量的取值只能为0或1，那么信号量就成为了互斥量；
- **事件** Event：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒**一个**等待中的线程，然后自动恢复为未激发状态。
- **临界区** Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直到临界区对象被释放。

#### 互斥量和临界区的区别？

互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。

## 1.14 ★★★什么是用户态和内核态？

为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU划分了用户态和内核态两个权限等级。

- 用户态只能受限地访问内存，且不允许访问外围设备，没有占用CPU的能力，CPU资源可以被其它程序获取；
- 内核态可以访问内存所有数据以及外围设备，也可以进行程序的切换。

所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用**陷阱指令**，CPU切换到内核态，执行相应的服务，再切换回用户态并返回系统调用的结果。

#### 为什么要用用户态和内核态？

- 安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源；
- 封装性：用户程序不需要实现更加底层的代码；
- 利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交给操作系统调度更加方便。

#### 如何从用户态切换到内核态

- 系统调用：比如读取命令行输入。本质上还是通过中断实现
- 用户程序发生异常时：比如缺页异常
- 外围设备的中断：外围设备完成用户请求的操作之后，会向CPU发出中断信号，这时CPU会转去处理对应的中断处理程序

## 1.15 ★★☆ 磁盘调度

过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减小寻道时间的调度算法：

- 先来先服务
- 最短寻道时间优先
- 电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

# 2 Linux

## 2.1 ★★★ 僵尸进程与孤儿进程的区别，从 SIGCHLD 分析产生僵尸进程的原因。

#### 僵尸进程ß

一个子进程结束后，它的父进程并没有等待它（调用wait或者waitpid），那么这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该**进程的进程ID、终止状态以及资源利用信息**(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。

危害：占用进程号，而系统所能使用的进程号是有限的；占用内存。

以下情况不会产生僵尸进程：

- 该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用Init进程接管，成为该进程的父进程，并且会调用wait等待其结束。

- 父进程调用wait或者waitpid等待子进程结束（需要每隔一段时间查询子进程是否结束）。wait系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid则可以加入```WNOHANG```(wait-no-hang)选项，如果没有发现结束的子进程，就会立即返回，不会将调用waitpid的进程阻塞,默认情况也是挂起父进程等待，直到有子进程结束。

  ```java
  pid_t waitpid(pid_t pid, int *status, int options);  //option可选择设置waitpid不堵塞
  返回：如果成功，返回子进程的ID；如果option设置为WNOHANG,则为0；如果其他错误，则为-1。
  ```

  pid>0:还是等待指定pid的子进程

  pid=-1:等待任一子进程

  pid=0:等待组ID等于pid的任一子进程；

- 子进程结束时，系统会产生```SIGCHLD```(signal-child)信号，可以注册一个信号处理函数，在该函数中调用waitpid，等待所有结束的子进程（**注意：一般都需要循环调用waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收**）；

- 也可以用```signal(SIGCLD, SIG_IGN)```(signal-ignore)通知内核，表示忽略```SIGCHLD```信号，那么子进程结束后，内核会进行回收。

#### 孤儿进程

一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程会被Init（进程ID为1）接管，当这些孤儿进程结束时由Init完成状态收集工作。



## 2.2 ★★★ Fork（）的底层实现和返回值

https://blog.csdn.net/Dawn_sf/article/details/78709839

### fork()返回值

pid=fork();

| 返回值 | 含义                          |
| ------ | ----------------------------- |
| -1     | 创建失败                      |
| 0      | 当前在子进程中                |
| id     | 当前在父进程中,id是子进程的id |

**fork成功调用后会返回两个值**

由于在复制时复制了父进程的堆栈段，所以两个进程都停留在fork函数中，等待返回.因为fork函数会返回两次,一次是在父进程中返回，另一次是在子进程中返回，这两次的返回值不同. 从fork函数开始以后的代码父子共享，既父进程要执行这段代码，子进程也要执行这段代码.(子进程获得父进程数据空间，堆和栈的副本. 但是父子进程并不共享这些存储空间部分. 父，子进程共享代码段.)现在很多现实并不执行一个父进程数据段，堆和栈的完全复制. 


### fork()底层实现



![img](https://img-blog.csdn.net/20171204170716379)

## 2.3 ★★★ kill 命令

kill需要进程号作为参数，killall需要进程名字作为参数

kill (-n）pid  

n表示发送信号序号 如果不加默认是15（**SIGTERM**）、19（**SIGSTOP**）

```java
kill 785 //让进程id为785的进程自己正常退出  
kill -9 785// 9表示SIGKILL 立即结束进程
killall -9 mozilla //mozilla是进程的名称
```

