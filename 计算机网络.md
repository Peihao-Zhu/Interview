[TOC]



# 1 基础

## 1.1 ★★★ 各层协议的作用，以及 TCP/IP 协议的特点。	

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/0fa6c237-a909-4e2a-a771-2c5485cd8ce0.png)

####  五层协议

- 应用层：为特定应用程序提供数据传输服务，如HTTP、DNS。数据单位为报文



- 传输层：为进程提供通用数据传输服务。运输层包括两种协议：传输控制协议TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP提供完整性服务，UDP提供及时性服务。

重要知识点：

1. **传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输以及端到端的差错控制和流量控制问题；**
2. **包括的主要协议：TCP、UDP**
3. **重要设备：网关**



- 网络层：为主机提供数据传输服务。把传输层传下来的报文段或者用户数据报封装成分组

功能：寻址、路由选择。它提供的服务使传输层不需要了解网络中的数据传输和交换技术。**IP协议仅仅提供不可靠、无连接的传送服务。**IP协议主要功能：无连接数据报传输、数据报路由选择和差错控制。与IP协议配套使用还有ARP协议，ICMP，IDMP等协议

重要知识点：

1. **网络层负责对子网间的数据包进行路由选择。此外，网络层还可以实现拥塞控制、网际互连等功能；**
2. **基本数据单位为IP数据报；**
3. **包含的主要协议**：

**IP协议（Internet Protocol，因特网互联协议）;**

**ICMP协议（Internet Control Message Protocol，因特网控制报文协议）;**

**ARP协议（Address Resolution Protocol，地址解析协议）;**

**RARP协议（Reverse Address Resolution Protocol，逆地址解析协议）。**

   4.**重要的设备：路由器。**



- **数据链路层：**主机之间有很多链路，链路层协议就是同一链路的主机提供数据传输服务

  功能：如何将数据组合成数据块，在数据链路层中称这种数据块为**帧（frame**），帧是数据链路层的传送单位；如何控制帧在物理信道上的传输，包括如何处理传输差错，如何调节发送速率以使与接收方相匹配；以及在两个网络实体之间提供数据链路通路的建立、维持和释放的管理。数据链路层在不可靠的物理介质上提供可靠的传输。该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。

  重要知识点：

  1. 数据链路层为网络层提供可靠的数据传输
  2. 基本数据单位为帧
  3. 主要协议：以太网协议

  

- 物理层：怎样在传输媒体上传输数据比特流，**该层为上层协议提供了一个传输数据的可靠的物理媒体。简单的说，物理层确保原始的数据可在各种物理媒体上传输。**物理层记住两个重要的设备名称，中继器（Repeater，也叫放大器）和集线器。

#### TCP/IP协议的特点

https://blog.csdn.net/qq_33857502/article/details/57414162

（1）TCP/IP协议不依赖于任何特定的计算机硬件或操作系统，提供开放的协议标准，即使不考虑Internet，TCP/IP协议也获得了广泛的支持。所以TCP/IP协议成为一种联合各种硬件和软件的实用系统。

（2）TCP/IP协议并不依赖于特定的网络传输硬件，所以TCP/IP协议能够集成各种各样的网络。用户能够使用以太网（Ethernet）、[令牌环网](http://baike.baidu.com/view/115033.htm)（Token Ring Network）、拨号线路（Dial-up line）、[X.25](http://baike.baidu.com/view/175390.htm)网以及所有的网络传输硬件。

（3）统一的网络地址分配方案，使得整个TCP/IP设备在网中都具有惟一的地址

（4）标准化的高层协议，可以提供多种可靠的用户服务。

#### 各个网络层的相关协议

- 应用层：常见协议：

  | 应用             | 应用层协议 | 端口号  | 传输层协议 | 备注                        |
  | ---------------- | ---------- | ------- | ---------- | --------------------------- |
  | 域名解析         | DNS        | 53      | UDP/TCP    | 长度超过 512 字节时使用 TCP |
  | 动态主机配置协议 | DHCP       | 67/68   | UDP        |                             |
  | 简单网络管理协议 | SNMP       | 161/162 | UDP        |                             |
  | 文件传送协议     | FTP        | 20/21   | TCP        | 控制连接 21，数据连接 20    |
  | 远程终端协议     | TELNET     | 23      | TCP        |                             |
  | 超文本传送协议   | HTTP       | 80      | TCP        |                             |
  | 简单邮件传送协议 | SMTP       | 25      | TCP        |                             |
  | 邮件读取协议     | POP3       | 110     | TCP        |                             |
  | 网际报文存取协议 | IMAP       | 143     | TCP        |                             |

- 传输层：TCP/UDP

- 网络层：IP、ARP、NAT（解决内网IP到外网IP的映射，分为静态转换和动态转换）、RIP...

<details>
<summary>路由器、交换机位于哪一层？</summary>


- 路由器网络层，根据IP地址进行寻址；
- 交换机数据链路层，根据MAC地址进行寻址

## 1.2 ★★☆ 以太网的特点，以及帧结构。	

以太网是一种星型拓扑结构的**局域网**，早期使用集线器进行连接，作用于比特而不是帧，当一个比特到达接口时，集线器生成该比特并将其强度放大，从而扩大网络距离。

 

现在以太网使用交换机替代了集线器，交换机是一种链路层设备，不会发生碰撞，会根据MAC地址进行存储转发

![img](file:////private/var/folders/gw/tm5w3wzx75b28wcz_7klvkxm0000gn/T/com.kingsoft.wpsoffice.mac/wps-zhupeihao/ksohtml/wpsi4HsWs.jpg) 

- 类型：标记上层使用的协议
- 数据：长度在46-1500之间
- FCS：帧检验序列，使用CRC（循环冗余）检验

## 1.3 ★★☆ 集线器、交换机、路由器的作用，以及所属的网络层。	

https://blog.csdn.net/clubsondy/article/details/542615

 

**集线器：**

物理层

没有智能处理能力，数据只是电流而已，当一个端口的电流传到集线器中时，只是简单的将电流传送到其他端口，至于其他端口连接的计算机接不接收就不管了。

共享性模式，就是一个端口在向另一个端口发送数据时，其他端口处于等待状态。

 

**交换器：**

链路层

具有自学习能力，学习得是交换表的内容，交换表中存储着MAC地址到接口的映射。因为是自学习，所以交换机是一种即插即吧设备，不需要管理员手动配置交换表内容。

下图：交换机有4个接口，主机A向主机B发送数据帧时，交换机把主机A的MAC的地址和接口1的映射写入交换表，此时没有主机B的表项，所以主机A发送广播帧，主机C和主机D会丢弃该帧，主机B回应该帧向A发送数据包时，交换机查找交换表得到主机A映射的接口为1，发送数据到接口1，同时在交换表中添加主机B的MAC地址到接口2的映射。

![img](file:////private/var/folders/gw/tm5w3wzx75b28wcz_7klvkxm0000gn/T/com.kingsoft.wpsoffice.mac/wps-zhupeihao/ksohtml/wpsqd1GT5.jpg) 

 

**路由器：**

工作在网络层，能够连接不同类型的网络，能够选择数据传送的路径。能理解数据中的IP地址，如果接收到一个数据包，就检查其中的IP地址，如果目标地址是本地网络，就不理会，如果是其他网络，就会将数据包转发出本地网络。

集线器和交换机一般用于连接以太网，路由器可以连接不同类型的局域网，广域网。不同类型的网络，传送的数据单元-帧的格式大小也不同。

路由器有路径选择能力，从一个节点到另一个节点有不同的路由算法。

## 1.4 ★★☆ IP 数据数据报常见字段的作用。	

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/85c05fb1-5546-4c50-9221-21f231cdc8c5.jpg)

- 版本：IPv4和IPv6
- 首部长度：占4个位，最大值位15.值为1表示1个32位长度，也就是4字节。因为固定部分长度为20字节，所以该值最小为5
- 区分服务：用来获得更好的服务，一般不用
- 总长度，包括首部长度和数据部分长度
- 生存时间TLL：防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数位单位，当TLL为0就丢弃数据包。
- 协议：携带的数据上交给哪个协议进行处理，如ICMP、TCP、UDP。
- 首部检验和：数据包每经过一个路由器，都要重新计算检验和，检验和不包含数据部分可以减少计算量
- 标识：在数据报过长而发生分片情况下，相同数据报的不同分片具有相同的标识符
- 片偏移：和标识符一起，用于发生分片的情况。单位是8字节。

![img](file:////private/var/folders/gw/tm5w3wzx75b28wcz_7klvkxm0000gn/T/com.kingsoft.wpsoffice.mac/wps-zhupeihao/ksohtml/wpsNcZp1d.jpg) 

## 1.5 ★☆☆ ARP 协议的作用，以及维护 ARP 缓存的过程。

**ARP实现由IP地址得到MAC地址。**

**网络层实现主机间的通信，而链路层实现具体每段链路之间的通信。**在通信过程中，IP数据报的原地址和目的地址不变，而MAC地址会随着链路的改变而改变。

每个主机都有一个ARP高速缓存，里面有局域网上各主机和路由器IP地址到MAC地址的映射表。

如果主机A知道主机B的IP地址，但是ARP高速缓存没有该IP地址到MAC地址的映射，就会通过**广播方式发送ARP请求分组**，这个请求分组中会包括原IP地址到其MAC地址的映射；主机B收到该请求后会首先保存这一对映射，然后发送ARP响应分组给主机A，告知其MAC地址，随后主机A向高速缓存写入主机B的IP地址到MAC地址的映射，要是主机A一直收不到响应，表示ARP查询失败。如果这个主机不再他的局域网内，那么需要通过ARP找到位于本局域网上的某个路由器的硬件地址，然后把分组发送给路由器，让这个路由器分组转发给下一个网络。剩下的工作由下一个网络来做。

ARP缓存是有生存期的，生存期结束后将在重复上面的过程。



**逆地址解析协议，即RARP**

**功能和ARP协议相对，其将局域网中某个主机的物理地址转换为IP地址**，比如局域网中有一台主机只知道物理地址而不知道IP地址，那么可以通过RARP协议发出征求自身IP地址的广播请求，然后由RARP服务器负责回答。

RARP协议工作流程：

（1）给主机发送一个本地的RARP广播，在此广播包中，声明自己的MAC地址并且请求任何收到此请求的RARP服务器分配一个IP地址；

（2）本地网段上的RARP服务器收到此请求后，检查其RARP列表，查找该MAC地址对应的IP地址；

（3）如果存在，RARP服务器就给源主机发送一个响应数据包并将此IP地址提供给对方主机使用；

（4）如果不存在，RARP服务器对此不做任何的响应；

（5）源主机收到从RARP服务器的响应信息，就利用得到的IP地址进行通讯；如果一直没有收到RARP服务器的响应信息，表示初始化失败。

### ARP攻击

https://blog.csdn.net/zhydream77/article/details/85334042

- 诈骗攻击：经过发送伪造的ARP包来诈骗路由和原始主机，让原始主机认为这是一个合法的主机，便完成了诈骗，这种诈骗多发生在同一网段内，因为路由不会把本网段的包向外转发，当然完成不一样网段的攻击也有办法，便要经过ICMP协议来告诉路由器从头挑选路由。
- MAC Flooding：使交换机的ARP表溢出，全网不能正常通讯

## 1.6 ★★☆ ICMP 报文种类以及作用；和 IP 数据报的关系；Ping 和 Traceroute 的具体原理。	

ICMP是为了检测网络通信故障和实现链路追踪，被封装在IP数据报中。最典型的应用是PING和traceroute。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e3124763-f75e-46c3-ba82-341e6c98d862.jpg)

 

ICMP种类：差错报告报文和询问报文

 

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/aa29cc88-7256-4399-8c7f-3cf4a6489559.png)

 

#### 1.Ping

测试两台主机的联通性，Ping的原理是通过向目的主机发送ICMP echo请求报文，目的主机收到后发送Echo回答报文。Ping会根据时间和成功响应的次数估算出数据报往返时间以及丢包率。

 

#### 2.Traceroute

用来跟踪一个分组从源点到终点的路径。Traceroute发送的IP数据报封装的是无法交付的UDP用户数据报，并由目的主机发送终点不可达差错报告报文。

- 源主机向目的主机发送一连串的IP数据报。第一个数据报P1的生存时间TTL为1，当P1到达路径上第一个路由器R1是，就把他丢弃，并向源主机发送一个ICMP时间超过差错报告报文。
- 源主机接着发送第二个数据报P2，并把TTL设置为2，P2先到达R1，R1收下后把TLL减1在转发给R2，R2收下后TTL为0，把它丢弃，并向源主机发送一个ICMP时间超过差错报文。
- 不断执行这个步骤，直到数据报刚刚到达目的主机（目的主机不会转发数据报，不会吧TTL值减1，但是数据报封装的是无法交付的UDP，所以目的主机向源主机发送ICMP终点不可达差错报告报文），之后源主机就知道了目的主机所经过的路由器IP地址以及到达每个路由器的往返时间

## 1.7 ★★★ UDP 与 TCP 比较，分析上层协议应该使用 UDP 还是 TCP。	

#### TCP的UDP的区别

1. TCP是面向连接的，UDP是无连接的

2. TCP是可靠的，UDP是不可靠的

3. TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；

4. **TCP是面向字节流的，UDP是面向报文的**

（面向字节流指发送数据时以字节为单位，一个数据包可以拆分成若干组进行发送；UDP只能一个报文一次发完）

5. TCP有拥塞控制机制，UDP没有。

6. TCP首部开销（20字节）比UDP（8字节）大

7. UDP的主机不需要维持复杂的连接状态

  

 

**UDP（用户数据报协议）**：无连接的，尽最大可能交付，没有拥塞控制（对实施性应用很重要），面向报文（对应用程序传下来的报文不合并也不拆分，只是添加UDP首部），支持一对一、一对多、多对一和多对多通信。首部8个字节

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/d4c3a4a1-0846-46ec-9cc3-eaddfca71254.jpg)

 

 

**TCP（传输控制协议）**：面向连接，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看出字节流），TCP只能是点对点的通信。首部20个字节

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/55dc4e84-573d-4c13-a765-52ed1dd251f9.png)

 

- **序号** ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。

- **确认号** ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。

- **数据偏移** ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。

- **确认 ACK** ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。

- **同步 SYN** ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。

- **终止 FIN** ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。

- **窗口** ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。

  

#### TCP和UDP应用场景：

对实时性要求比较高的情况，选择UDP，如游戏，通信，实时视频流，即使出现传输错误也是可以容忍的；其他大部分情况，HTTP都是使用TCP

 

HTTP不能使用UDP，因为UDP是不可靠的，而HTTP是基于可靠的传输协议

 

使用UDP的应用层协议有：DNS（域名系统）、TFTP（简单文件传送协议）、RIP（路由信息协议）、DHCP（动态主机配置协议）、SNMP（简单网络管理协议）、NFS(网络文件系统)、IGMP（忘记组管理协议），此外在网络语音或视频通信中也使用UDP通信.

 

使用TCP的应用层协议有：HTTP（超文本传输协议）、FTP（文件传输协议）、SMTP（简单邮件传输协议）、TELNET（远程终端协议）.

 

**面向连接和无连接的区别。**

- 无连接的网络服务（数据报服务）：

每个数据包含目的地址，数据路由相互独立；网络经最大努力交付数据，但不保证送达、不保证先后顺序、不保证在时限内交付；网络发生拥塞时，可能将一些分组丢弃。

- 面向连接的网络服务（虚电路服务）

首先建立连接，所有的数据包经过相同的路径服务质量有较好的保证

## 1.8 ★★★ 理解三次握手以及四次挥手具体过程，三次握手的原因、四次挥手原因、TIME_WAIT 的作用。

### 三次握手

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e92d0ebc-7d46-413b-aec1-34a39602f787.png)

1. 第一次握手：Client将SYN=1 ACK=0，随机产生一个初始序列号x发送给Server，进入SYN_SENT
2. 第二次握手：Server收到Client的SYN=1以后，知道客户端请求建立连接，将自己的SYN置1，ACK置1，产生一个acknowledge number=x+1，并随机产生一个初始序列号y，发送给客户端，进入SYN_RCVD状态
3. 第三次握手：Client检查acknowledge number是否为序列号+1，ACK是否为1，检查正确后将ACK置1，产生一个acknowledge number=y+1,序列号为x+1，发送给服务器；进入Established状态；服务器检查ACK为1和acknowledge number=y+1，也进入Established状态,连接建立

 

#### 问TCP建立连接可以两次握手吗

 

不可以 有两个原因：

1.可能出现已失效的连接请求又传到了服务器端

client发出的第一个连接请求报文段并没有丢失，而是在某个网络节点长时间滞留了，以至到连接释放以后的某个时间才到达server。本身这已经是一个失效的报文段。但是server接受到此请求以后还以为是新的连接请求，于是向client发出确认报文，同意建立连接。如果采用两次握手，那么只要server确认，新的连接就建立了。由于client并没有发出建立连接的请求，所以不会理睬server，也不会向server发送数据，但是server却发出了建立连接的请求，并一直等待client的回复。这样server的很多资源就浪费了。

2.两次握手无法保证client正确收到第二次握手的报文（server端不知道），也无法保证client和server之间成功互换初始序列号

 

#### 可以采用四次握手吗

 

可以。但是会降低传输效率

四次握手是指在第二次握手时server只发送ACK和acknowledge number；而Server的SYN和初始序列好在第三次握手中发送。处于优化的目的，四次握手的二、三可以合并。

 

#### 第三次握手中，如果客户端的ACK未送达服务器，会怎样？

Server端；

由于Server没有收到ACK确认，因此会重发之前的SYN+ACK（默认重发五次，之后自动关闭连接进入CLOSED状态），client收到后会重新传ACK给server。

Client端，有两种情况：

1.在Server超时重发的过程中，如果CLient发送的数据，ACK为1，所以服务器收到数据后就进入extablished状态

2.在Server已经进入closed状态后，Client在向服务器发送数据，服务器会以RST包应答。

 

#### 如果已经建立了连接，但客户端出现了故障怎么办？

服务器每收到一次客户端的请求后都会复位一个计数器，时间通常设置2小时，若2小时还没有收到客户端数据，服务器会发送一个探测报文段，以后每隔75s发送一次。若一连发送10个探测报文段都没有反应，服务器就会关闭连接。

 

#### 初始序列号是什么？

TCP的连接一方A，随机选择一个32位序列号作为发送数据的初始序列号（Initial Sequence Number，ISN），比如100，以该序列号为原点，对要传送的数据进行编号：1001、1002...三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；同时在进行数据传输时，A还可以确认B收到的每一个字节，如果A收到了B的确认编号（acknowledge number）是2001，就说明编号为1001-2000的数据已经被B成功接受。

 

### 四次挥手

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f87afe72-c2df-4c12-ac03-9b8d581a8af8.jpg) 

1. 第一次挥手：Client将FIN置1，发送一个seq给Server；进入FIN——WAIT——1状态
2. 第二次挥手：Server收到FIN，发送一个ACK；进入CLOSE_WAIT状态。此时客户端没有要发送的数据，但仍可以接受服务器发送的数据
3. 第三次挥手：Server将FIN置1，发送一个seq给Client；进入LAST_ACK状态
4. 第四次挥手：Client收到FIN后，进入TIME_WAIT状态；接着将ACK置1，发送一个acknowledge number=序列号+1；服务器收到后确认acknowledge number，变为CLOSED状态，不再向客户端发送数据。客户端等待2*MSL(报文段最长寿命)，也进入CLOSED状态，完成四次挥手。

 

#### 为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSED_WAIT状态的意义）

当服务器收到客户端断开连接的请求时，可能数据还没发送完，所以回复ACK，表示接收到断开连接的请求。等到数据发完后在发FIN，断开和服务器的数据传输。

 

#### 如果第二次挥手时服务器的ACK没有送达客户端会怎样

客户端没有收到ACK，会重新发送FIN请求

 

#### 客户端的TIME_WAIT状态意义是什么

客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由.

1.确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生.

2.等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文(防止客户端提前结束的话，服务器端会重复发送FIN报文)。

**MSL(Maximum Segment Lifetime)**，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

## 1.9 ★★★ 可靠传输原理，并设计可靠 UDP 协议	

https://blog.csdn.net/pangyemeng/article/details/50387078

 

### TCP实现可靠传输的原理

数据包检验、确认机制（对失序数据包重排序，接收到数据后，会发送一个确认）、超时重传机制、滑动窗口，流量控制

**1.数据包校验**

发送方将伪首部、TCP首部、TCP数据 使用累加和检验的方式计算出一个数字，存放在TCP首部的校验和字段中。接受方使用经过同样的过程计算校验和与首部该字段的值进行比较，如果不一致就说明数据传输错误。

但是即使校验和相同，也不能保证数据是准确的，因为累加和校验本身就存在缺陷，很可能两个位置的数据交换以下，校验结果还是正确的。所以为了安全可以在应用层增加额外的数据校验方式（使用MD5摘要）。

**2.超时重传**

如果一个已经发送报文段在一段时间内没有收到确认，就会重传这个报文段。

详细机制：

TCP协议会设立重传定时器，在发送一个报文段的同时启动重传定时器，如果在重传定时器超时前收到了确认报文就关闭该定时器；反之就会重传该报文段。在重传时间的设定上，TCP具有自适应性，会根据当前互联网的通信情况，给出合适的重发时间。对于重传定时器的初值设定较多采用Jacobson的算法。。。。

 

**3.确认机制**

TCP能确保每个数据段都到达目的地，实现方式是目的主机在接收到数据后会发送确认消息。

举例：

如果发送报文段时序列号是1000，传输的连续数据段有100个，当目的主机接受了这100个数据以后会发送确认消息，此时的acknoeledge number=1000+100+1=1101，表示期待接受的下一个字节（期待确认）

**4.滑动窗口**

窗口是缓存的一部分，发送方和接收方都有，用来暂时存放字节流。接收方会通过TCP报文段中的窗口字段告诉发送方自己的窗口大小。

 

**发送窗口**包括已发送但尚未收到确认的数据和允许发送但尚未发送的数据，如果有数据收到了确认，窗口就会右移。

**接受窗口**只会对<u>最后一个按序到达的字节进行确认</u>，例如接受窗口收到字节{31,34,35},只会接受{31},只对31进行确认。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg)

 

 

### 设计可靠的UDP协议

传输层无法保证数据的可靠传输，通过应用层来实现，实现的方式就按照上面讲的三个实现可靠传输的机制：确认机制、超时重传机制、滑动窗口；

1.添加seq/ack机制，确保数据发送到目的端

2.添加发送和接受缓冲区，

3.添加超时重传机制

## 1.10 ★★☆ TCP 拥塞控制的作用，理解具体原理。

https://blog.csdn.net/m0_37962600/article/details/79993310?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase

#### 作用： 

防止过多的数据注入到网络中，使路由器或链路过载。

 

#### 拥塞控制原理：

通过四个算法来实现TCP拥塞控制：慢开始、拥塞避免、快重传、快恢复。

发送方维护一个拥塞窗口(cwnd)状态变量，发送方窗口决定了实际发送方能发送多少数据。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/910f613f-514f-4534-87dd-9b4699d59d31.png)

**1.慢开始**

最初令cwnd=1，发送方开始只能发送一个报文段；当收到确认后，将cwnd加倍。因此之后发送方能发送的报文使2、4、8...

 

当rwnd足够大的时,即接收方有足够大的接受缓存，不会发生流量控制，为了防止cwnd的增长引起网络阻塞，需要设置一个慢开始阈值(ssthresh)

- 当cwnd<ssthresh 使用慢开始算法
- 当cwnd>ssthresh 停止使用慢开始，使用拥塞避免算法

 

**局限性：**

需要获得网络内部流量分布信息，浪费可用的网络容量，额外开销；估算合理的ssthresh不容易

注意：

1）接收端窗口rwnd，又称通知窗口awnd，使接收端根据目前的接受缓存大小允许的最新窗口值，是来自接收端的流量控制

2）拥塞窗口cwnd使发送端根据其估计的网络阻塞程度而设置的窗口值，来自发送端的流量控制

3）cwnd初始可以设置为一个报文段(实质是TCP数据包每次能够传输的最大数据分段，不包括TCP首部，只出现在SYN报文段中)

 

**2.拥塞避免**

每经过一个往返时间RTT，让cwnd+1

无论是慢启动还是拥塞避免，一旦出现拥塞(发送超时),就把ssthresh设置为cwnd的一半，然后cwnd重新设为1，进行慢开始，这样能迅速减少网络中的数据传输。拥塞窗口是按照线性规律增长。

 

AIMD（加法增大乘法减小）：乘法减小：网络发现超时，就将ssthresh减少一半，cwnd为1；加法增大：cwnd缓慢增大，以防网络过早拥塞

 

拥塞避免算法不能完全避免拥塞，只能使网络不容易产生拥塞。

 

**3.快重传（重传失序报文）**

在接收方，要求每次接收到的报文段都对最后一个已收到的有序报文段进行确认。

在发送方如果收到三个重复确认（不用等到重传计时器到期），就知道下一个报文段丢失，此时执行快重传。

如下图M3发生丢失，所以连续收到3个M2，立即重传M3

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f61b5419-c94a-4df1-8d4d-aed9ae8cc6d5.png)

 

**4.快恢复**

当收到三个重复确认后，ssthresh=cwnd/2，cwnd=ssthresh,直接进入拥塞避免。

#### 为什么收到三个重复确认后，是直接进入拥塞避免而不是慢开始？

因为这种情况下有三个重复确认，表示当前网络环境是好的，不断有数据报送达，所以网络没有拥塞，没必要慢开始，可以直接执行拥塞避免。也有些把cwnd设置为ssthresh+3*MSS,因为既然已经收到了3个重复确认，表示这三个分组不再消耗网络资源，而是停留在接收方的缓存中，可以把拥塞窗口扩大些。

 

**注意：**

慢开始和快恢复指的是cwnd的值，并不是cwnd的增长率，慢开始设为1，而快恢复设为ssthresh

## 1.11 ★★☆ DNS 的端口号；TCP 还是 UDP；作为缓存、负载均衡。	

DNS端口号53 当长度超过512字节使用TCP。

- DNS区域传输使用TCP协议：

次域名服务器会定时向主域名服务器进行查询以了解数据是否变动。如有变动，会执行一次区域传送，进行数据同步，使用TCP，因为数据同步传送的数据量比一个请求应答的数据量要多的多。并且TCP是可靠传输，保证数据的准确性。

- 域名解析使用UDP协议：

客户端向DNS服务器查询域名，一般返回的内容不超过512字节（如果超过了，会截断，那么用户得到的DNS应答是不完整的），用UDP传输，不用三次握手，这样DNS服务器负载更低，响应更快。理论上说客户端也可以指定向DNS服务器查询时用TCP，但事实上很多DNS服务器配置时，仅可以UDP查询。

 

**如果想要UDP传送超过512字节的数据，可以在DNS字段中增加报文ID，用于分片**

 

## 1.12 ★★☆ TCP如何实现流量控制	

![img](file:////private/var/folders/gw/tm5w3wzx75b28wcz_7klvkxm0000gn/T/com.kingsoft.wpsoffice.mac/wps-zhupeihao/ksohtml/wpsl1XCDr.jpg) 

TCP首部中有一个窗口字段--占2个字节。用来控制发送方发送的数据量。接受方根据自己的缓存空间大小确定接受窗口的大小。

使用**滑动窗口协议**实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接受窗口，在返回ACK时，会将接受窗口的大小放在TCP报文的窗口字段中。

发送窗口的上限为接收窗口和拥塞窗口中的较小值。

 

#### 什么是零窗口（接收窗口为0会怎么样）？

如果接受方没有能力接受数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计数器，到期后发送一个大小为1字节的探测数据报，以查看接受窗口的状态。如果接收方能接受数据买就会在返回报文中更新接受窗口大小，恢复数据传送。

## 1.13 ★★★ IP地址、子网掩码以及子网划分

#### IP地址

首先了解一下IP地址的分类：A,B,C,D类地址

A类地址以0开头，第一个字节作为网络号，地址范围为：0.0.0.0~127.255.255.255；

B类地址以10开头，前两个字节作为网络号，地址范围是：128.0.0.0~191.255.255.255;

C类地址以110开头，前三个字节作为网络号，地址范围是：192.0.0.0~223.255.255.255。

D类地址以1110开头，地址范围是224.0.0.0~239.255.255.255，D类地址作为组播地址（一对多的通信）；

E类地址以11110开头，地址范围是240.0.0.0~255.255.255.255，E类地址为保留地址，供以后使用。

**注意：只有A、B、C有网络号和主机号之分，D和E类地址没有划分网络号和主机号。**



**1）广播地址**

广播地址通常成为直接广播地址，是为了区分受限广播地址。

广播地址的主机号全为1，当向某个网络的广播地址发送消息时，该网络内的所有主机都能收到该广播信息

**2）255.255.255.255**

这是受限广播地址。与一般广播地址的区别在于，受限广播地址只能用于本地网络，路由器不会转发以受限广播地址为目的地址的分组；一般广播地址既可在本地广播，也可跨网段广播。例如：主机192.168.1.1/30上直接广播数据包后，另外一个网段192.168.1.5/30也能收到该数据报；若发送受限广播数据报，则不能收到。

注：一般的广播地址（直接广播地址）能够通过某些路由器（当然不是所有的路由器），而受限的广播地址不能通过路由器。

**3）0.0.0.0**

常用于表示 **无效的，未知的或是没有指定目标IP地址**。用处主要有：

- 本机所有IP

  0.0.0.0在一台服务器中的左右，就是指代这台服务器所有的IP。

- 默认路由

  路由表记录了数据报下一跳应该去哪，包含目标地址的网络ID，子网掩码和下一跳地址的接口。

  假设一个IP匹配了多条路由规则，那么子网越小的越优先。而如果配置了0.0.0.0->111.222.1.254这样的路由规则，表示当解析不到任何精确路由规则时，下一跳都到111.222.1.254

- DHCP

  https://www.cnblogs.com/wajika/p/6537085.html

  当一个网络设备第一次启动的时候，没有配置IP，需要通过DHCP协议向同一局域网内的DHCP服务器索要IP地址。但DHCP是建立在UDP上的，需要有IP才能发送这个包，这时这个网络设备和DHCP会按照下图的顺序进行包的发送。

![DD451E5B385F93C34901CE1425D6E0C1](/Users/zhupeihao/Library/Containers/com.tencent.qq/Data/Library/Caches/Images/DD451E5B385F93C34901CE1425D6E0C1.jpg)

**4）回环地址**

127.0.0.0/8被用作回环地址，回环地址表示本机的地址，常用于对本机的测试，用的最多的是127.0.0.1（localhost）。

什么意思呢？形象地说就是发送数据包是从应用层->数据链路层自上而下一层层按照程序封装的,当到了网络层，发现目标IP地址是127.0.0.1,就不再继续向下封装了，而是把包丢给需要像上层解析的队列中。

**5）A、B、C类私有地址**

私有地址(private address)也叫专用地址，它们不会在全球使用，只具有本地意义。

A类私有地址：10.0.0.0/8，范围是：10.0.0.0~10.255.255.255

B类私有地址：172.16.0.0/12，范围是：172.16.0.0~172.31.255.255

C类私有地址：192.168.0.0/16，范围是：192.168.0.0~192.168.255.255

### 子网掩码及网络划分

**什么是子网掩码？**

子网掩码是标志两个IP地址是否同属于一个子网的，也是32位二进制地址，其每一个为1代表该位是网络位，为0代表主机位。它和IP地址一样也是使用点式十进制来表示的。如果两个IP地址在子网掩码的按位与的计算下所得结果相同，即表明它们共属于同一子网中。

**子网掩码的计算：**

对于无须再划分成子网的IP地址来说，其子网掩码非常简单，即按照其定义即可写出：如某B类IP地址为 10.12.3.0，无须再分割子网，则该IP地址的子网掩码255.255.0.0。如果它是一个C类地址，则其子网掩码为 255.255.255.0。其它类推，不再详述。下面我们关键要介绍的是一个IP地址，还需要将其高位主机位再作为划分出的子网网络号，剩下的是每个子网的主机号，这时该如何进行每个子网的掩码计算。

下面总结一下有关子网掩码和网络划分常见的面试考题：

**1）利用子网数来计算**

在求子网掩码之前必须先搞清楚要划分的子网数目，以及每个子网内的所需主机数目。

(1) 将子网数目转化为二进制来表示;

如欲将B类IP地址168.195.0.0划分成27个子网：27=11011；

(2) 取得该二进制的位数，为N；

该二进制为五位数，N = 5

(3) 取得该IP地址的类子网掩码，将其主机地址部分的的前N位置1即得出该IP地址划分子网的子网掩码。

将B类地址的子网掩码255.255.0.0的主机地址前5位置 1，得到 255.255.248.0

**2）利用主机数来计算**

如欲将B类IP地址168.195.0.0划分成若干子网，每个子网内有主机700台：

(1) 将主机数目转化为二进制来表示；

700=1010111100；

(2) 如果主机数小于或等于254（注意去掉保留的两个IP地址），则取得该主机的二进制位数，为N，这里肯定 N<8。如果大于254，则 N>8，这就是说主机地址将占据不止8位；

该二进制为十位数，N=10；

(3) 使用255.255.255.255来将该类IP地址的主机地址位数全部置1，然后从后向前的将N位全部置为 0，即为子网掩码值。

将该B类地址的子网掩码255.255.0.0的主机地址全部置1，得到255.255.255.255，然后再从后向前将后 10位置0,即为：11111111.11111111.11111100.00000000，即255.255.252.0。这就是该欲划分成主机为700台的B类IP地址 168.195.0.0的子网掩码。

**3）还有一种题型，要你根据每个网络的主机数量进行子网地址的规划和计算子网掩码。这也可按上述原则进行计算。**

比如一个子网有10台主机，那么对于这个子网需要的IP地址是：

10＋1＋1＋1＝13

**注意：加的第一个1是指这个网络连接时所需的网关地址，接着的两个1分别是指网络地址和广播地址。**

因为13小于16（16等于2的4次方），所以主机位为4位。而256－16＝240，所以该子网掩码为255.255.255.240。

如果一个子网有14台主机，不少人常犯的错误是：依然分配具有16个地址空间的子网，而忘记了给网关分配地址。这样就错误了，因为14＋1＋1＋1＝17，17大于16，所以我们只能分配具有32个地址（32等于2的5次方）空间的子网。这时子网掩码为：255.255.255.224。

## 1.14 ★★☆  DHCP/远程登录协议/电子邮件协议

#### DHCP

DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。

DHCP 工作过程如下：

1. 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。
2. DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。
3. 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。
4. DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/23219e4c-9fc0-4051-b33a-2bd95bf054ab.jpg)

![DD451E5B385F93C34901CE1425D6E0C1](/Users/zhupeihao/Library/Containers/com.tencent.qq/Data/Library/Caches/Images/DD451E5B385F93C34901CE1425D6E0C1.jpg)

#### 远程登录协议

TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。

TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。

#### 电子邮件协议

一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。

邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/7b3efa99-d306-4982-8cfb-e7153c33aab4.png)

##### 1)SMTP

SMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/ed5522bb-3a60-481c-8654-43e7195a48fe.png)

##### 2)POP3

POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。

##### 3)IMAP

IMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。

## 1.15 ★★☆ CRC计算

**CRC校验原理**

先在要发送的帧后面附加一个数，生成一个新帧发送给接收端。当然，这个附加的数不是随意的，它要使所生成的新帧能与发送端和接收端共同选定的某个特定数相除（模2除法）得到的余数。到达接收端后，再把接收到的新帧除以（同样采用“**模2除法**”）这个选定的除数。此时如果没有余数，表示数据传输正确；反之表示数据传输失败。

**模2除法**

https://blog.csdn.net/qq_33411687/article/details/82593466

其实简单的说就是被除数如果第一位是1，则商为1；反之商为0. 中间进行的运算时模2加减运算（其实就是异或匀速哪），每次被除数都要右移一位，最后如果位数小于除数了，就停止运算，结果就是余数。举例：111位余数，1011位商。

![img](https://img-blog.csdn.net/20170622115733149?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRF9sZW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

**注意：除数如果是4位，那么余数要凑够3位**

### CRC8计算

1. 先生成一个除数（多项式），最高位和最低位必须是1。假设11001
2. 要传送的数据后面加上多项式的位数-1，即加4位0得到新生成的帧
3. 新生成的帧对除数进行模2除法，得到最后的余数（作为校验码），填补在最后4位。发送到接收端
4. 接收端将这个帧与除数进行模2除法，得到的余数为0表示传输正确，否则表示数据在传输过程中出错

### CRC16计算

（1）预置1个16位的寄存器为十六进制FFFF（即全为1），称此寄存器为CRC寄存器；
（2）把第一个8位二进制数据（既通讯信息帧的第一个字节）与16位的CRC寄存器的低
       8位相异或，把结果放于CRC寄存器，高八位数据不变；
（3）把CRC寄存器的内容右移一位（朝低位）用0填补最高位，并检查右移后的移出位；
（4）如果移出位为0：重复第3步（再次右移一位）；如果移出位为1，CRC寄存器与多

    项式（例如：1010 0000 0000 0001）进行异或；
（5）重复步骤3和4，直到右移8次，这样整个8位数据全部进行了处理；
（6）重复步骤2到步骤5，进行通讯信息帧下一个字节的处理；
（7）将该通讯信息帧所有字节按上述步骤计算完成后，得到的16位CRC寄存器的高、低
       字节进行交换；
（8）最后得到的CRC寄存器内容即为：CRC码。

```
如果发送的数据为7E 00 05 60 31 32 33 计算CRC16结果应该是：5B3E
```

# 2 HTTP

## 2.1 ★★★ GET 与 POST 比较：作用、参数、安全性、幂等性、可缓存。

1. 幂等性：GET是 幂等的，即读取同一个资源，总是得到相同的数据，POST不是幂等的

2. 作用：GET一般从服务器获取资源，而POST有可能改变服务器上的资源

3. 参数：GET请求的数据附在URL之后，HTTP请求头中；POST请求的数据在请求体中

4. 安全性：GET请求可被缓存、收藏、保留到历史记录，且其请求数据明文出现在URL中。POST的参数不会保存，安全性相对较高

5. GET只允许ASCII字符，而POST对数据类型没有要求，也允许二进制数据

6. GET的长度有限制（操作系统或浏览器），POST没有限制

 

注意：幂等意味着对同一URL的多个请求应该返回同样的结果。

## 2.2 ★★☆ HTTP 状态码。

- 2xx状态码：操作成功。

200 OK ；

204 No Content 请求处理成功，但返回的响应报文不包含实体的主题内容。一般只需要从客户端往服务器发送消息，不需要服务器返回信息。

- 3xx状态码：重定向。

301 永久重定向；

302暂时重定向

- 4xx状态码：客户端错误。

400 Bad Request（请求报文中存在语法错误）；

401 Unauthorized（发送的请求需要有认证信息）；

403 Forbidden；

404 Not Found；

- 5xx状态码：服务端错误。

500服务器内部错误；

503服务不可用（服务器暂时处于超负荷正在停机维护）

 

## 2.3 ★★★ Cookie 作用、安全性问题、和 Session 的比较。

https://blog.csdn.net/resilient/article/details/85249842

 **什么是无状态协议**？

**无状态协议是指协议对事务处理没有记忆能力**。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 Http协议不像建立了socket连接的两个终端，双方是可以互相通信的，http的客户端只能通过请求服务器来获取相关内容或文件信息。

http协议这种特性有优点也有缺点，优点在于**解放了服务器，每一次请求“点到为止”不会造成不必要连接占用**，缺点在于**每次请求会传输大量重复的内容信息**。



**正文**

HTTP协议是无状态的，HTTP/1.1引入Cookie保存状态信息。Cookie是服务器发送到用户浏览器并保存到本地的一小块数据，他会在浏览器向同一服务器再次发送请求时被携带上。由于每次请求都会携带Cookie数据，因此会带来额外的开销。

**作用：**

- 会话状态管理（用户登陆状态、购物车、游戏分数或其他需要记录的信息）
- 个性化设置
- 浏览器行为跟踪

**安全性问题：**

cookie存储在浏览器端，可以通过脚本或者工具抓去获取该值。

可以通过javascript的 document.cookie来获取Cookie。可以将Cookie标记为HttpOnly，就不能被JavaScript脚本调用。一定程度上避免跨站脚本攻击XSS。标记Secure的Cookie只能通过被HTTPS协议加密过的请求发送给服务端。但即便设置了Secure标记，敏感信息也不应该通过Cookie传输，因为有其固有的不安全性

1.Cookie欺骗：获取cookie以后虽然不知道其含义，但是可以将这个cookie向服务器提交，冒充用户来访问进而获取隐私信息。

2.Cookie截获：cookie以纯文本的形式在浏览器和服务器之间传递，在web通信时很容易被非法用户截获。

3.Flash的内部代码隐患：在观看Flash动画是，其内部可能悄无声息的打开了极小的不易发现的页面，可以向远程服务器输入当前cookie用户信息。

**解决办法：**

1.cookie有效期不要设置过长

2.设置HttpOnly属性为true

3.设置复杂的cookie，加密cookie（key用uuid随机生成，value使用复杂组合如用户名+当前时间+cookie有效时间+随机数）

4.用户第一次登录时，保存ip+cookie加密后的token

5.seesion和cookie同时使用

6.如果网站支持https，尽可能使用https（设置cookie的Secure属性为true）

 

**Session**

存储在服务器，存储在服务器端更安全。可以存放在数据库或内存或者Redis中。

使用session维护用户登陆状态的过程如下

1. 用户进行登陆时，用户提交包含用户名和密码的表单，放入HTTP请求报文中
2. 服务器验证该用户名和密码，如果正确就把用户信息存储到Redis中，Key就是SessionID；
3. 服务器返回的响应报文的Set-Cookie首部字段包含了这个Session ID，客户端收到响应报文后将该Cookie值放入浏览器
4. 客户端之后对同一个服务器进行请求时都包含该cookie值，服务器收到后提取SessionID，从Redis中提取用户信息，继续之前的业务操作。

 

**Cookie和Session比较**

Session是服务器端保持状态的方案，Cookie是客户端保持状态的方案

Cookie保存在客户端本地，客户端请求服务器时会将Cookie一起提交；Session保存在服务端，通过检索Sessionid查看状态。保存Sessionid的方式可以采用Cookie，如果禁用了Cookie，可以使用URL重写机制（把会话ID保存在URL中）。

Cookie只能存储ASCII，Session可以存储任何类型数据

Cookie不要存储隐私数据

大型网站，用户所有的信息都存储在Session中，开销是非常大的，不建议将所有用户信息存储到Session中。

## 2.4 ★★☆ 缓存 的 Cache-Control 字段，特别是 Expires 和 max-age 的区别。ETag 验证原理。

**优点：**

- 缓解服务器的压力
- 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快；并且缓存服务器的位置通常比源服务器更新，比如浏览器缓存。

### Cache-Control 

HTTP/1.1 通过Cache-Control首部字段控制缓存。

1. 禁止进行缓存 no-store 规定不能对请求或响应的任何一部分进行缓存

2. 强制确认缓存 no-cache 缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效是才能使用该缓存对客户端的请求进行响应

3. 私有缓存和公共缓存  

   private：将缓存作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中 ；

   public ：规定资源作为公共缓存，可被多个用户使用，一般存储在代理服务器中

4. 缓存过期机制 

   max-age（相对日期，多少秒后过期）

- 指令出现在请求报文中，并且缓存资源的缓存时间小于该指令指定的时间，那么就接受该缓存
- 出现在响应报文中，表示缓存在服务器中保存的时间 

​		Expires（绝对日期，年月日小时...）

- Expires首部字段可用于告知缓存服务器该资源过期时间



HTTP/1.0，max-age会被忽略掉

HTTP/1.1，max-age会优先处理

如果服务器和客户端不同时间，还是采用max-age相对日期更好，因为两个采用的时间不一样

 

### ETag---缓存验证

ETag是资源的唯一标识符，URL不能唯一表示资源，例如 http://www.google.com/ 有中文和英文两个资源。

可以将缓存资源的ETag放入If-None-Mathch首部，服务器收到该请求后，判断缓存资源的ETag值和资源的最新ETag值是否一致，如果一致则表示缓存资源有效，返回304 Not Modified

Last-Modified首部字段也可以用于缓存验证，他包含在源服务器发送的响应报文中，表示源服务器对资源的最后修改时间。但是它是一种弱校验，只能精确到1秒，所以经常作为ETag的备用方案。如果响应首部字段里含有这个信息，客户端在后续的请求中会带上If-Modified-Since来验证缓存。服务器只在自己的Last-Modified 比 客户端请求的If-Modified-Since 晚才会返回最新的资源（**换句话说就是客户端发送请求的时候，服务器的缓存已经修改过了**），状态吗是200OK。如果请求的资源从那时起没有修改，就返回一个304Not Modified响应报文。

```html
Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT

If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT
```

 

## 2.5 ★★★ 长连接与短连接原理以及使用场景，流水线。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/HTTP1_x_Connections.png)

- HTTP/1.0默认是短连接的，如果需要使用长连接，则使用Connection：Keep-Alive。适用于数据库连接
- HTTP/1.1默认是长连接的，如果要断开连接，需要客户端或者服务器端提出断开，使用Connection：close;
- 默认情况下HTTP是按顺序发出的，下一个请求只有在收到响应后才会发出。但由于收到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，需要等待很长时间。流水线在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。



**注意：**

1. 长连接需要服务器和客户端都设置Connection：headers 为keep-Alive
2. 长连接其实是复用tcp，不用每次都重新握手，挥手。对于访问一个网站，有很多请求（请求网页，css，js，图片等资源），如果使用短连接的话，需要来来回回建立好多次TCP连接。



### **长连接是否是永久连接？**

不是，一般服务端都会设置keep-alive超时时间。超过指定的时间间隔，服务端就会主动关闭连接。同时服务端还会设置一个参数叫最大请求数，比如当最大请求数是300时，只要请求次数超过300次，即使还没到超时时间，服务端也会主动关闭连接。

### **在长连接场景下，客户端如何知道服务器已经发送完数据了？**

这时需要了解两个字段 **Content-Length** 和 **Transfer-Encoding**。

Content-Length在请求GET方法中不能使用，在请求POST方法中需要使用，同时常常出现在响应头中。Content-Length必须真实反应响应体的长度，如果为0就表示传送完毕了，该情况对于静态方法可以，但是对于动态资源，很难获取其长度，所以使用下面的方法。

Transfer-Encoding不建议在请求体中出现，因为不确定服务器能否解析；应该出现在响应头中，因为浏览器都能解析。<u>Transfer-Encoding: chunked</u>用在响应头中，表示响应体内容用分块传输。举例：传输一段文本内容“人的一生总是在追求自由的一生 So easy”

![分块传输示意图](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMDI5MTcxMTQwODc3?x-oss-process=image/format,png)

\r\n只是换行。21\r\n表示传送的分块大小 ，最后传送完毕也需要发送0\r\n告知客户端传送完毕。

### 长连接如何续期

TCP keepalive指的是TCP保活计时器（keepalive timer）。设想有这样的情况：客户已主动与服务器建立了TCP连接。但后来客户端的主机突然出故障。显然，服务器以后就不能再收到客户发来的数据。因此，应当有措施使服务器不要再白白等待下去。这就是使用保活计时器。服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两小时。若两小时没有收到客户的数据，服务器就发送一个探测报文段，以后则每隔75秒发送一次。若一连发送10个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。
linux中tcp_keepalive_time、tcp_keepalive_intvl、tcp_keepalive_probes都 可以自己设定，如果要续期，就重新设定tcp_keepalive_time的大小。



## 2.6 ★★★ HTTP 存在的安全性问题，和HTTPS的区别以及 HTTPs 的加密、认证和完整性保护作用。

HTTP的安全性问题

1. 使用明文通信，内容可能被窃听

2. 不验证通信方的身份，通信方可能被伪造

3. 无法证明报文的完整性，报文可能遭篡改

 

HTTP与HTTPS区别

1.端口不同：HTTP使用80端口，HTTPS使用443端口

2.HTTP是明文传输，HTTPS运行在SSL（Secure Socket Layer），添加了加密和认证机制

3.HTTPS由于加密解密会带来更大的CPU和内存消耗

4.HTTPS通信需要证书，一般需要向证书颁发机构购买。

 

HTTPS的连接过程

1.客户端向服务器发送请求，同时发送客户端支持的一套加密规则（包括对称加密、非对称加密、摘要算法）；

2.服务器从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里包含了网站地址，加密公钥（用于非对称加密），以及证书的颁发机构等信息（证书私钥只能用于服务器端加密）

3.客户端验证服务器的合法性，包括：证书是否过期，CA是否可靠，发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”，服务器证书上的域名是否和服务器的实际域名相匹配。

4.如果证书受信任，或者用户接受了不受信任的证书，浏览器会生成一个随机密钥（用于对称算法），并用服务器提供的公钥加密（采用非对称算法对密钥加密）；使用Hash算法对握手信息进行摘要计算，并对摘要使用之前产生的密钥加密（对称算法）；将加密后的随机密钥和摘要一起发送给服务器。

5.服务器用自己的私钥解密，得到对称算法的密钥，用这个密钥解密出Hash摘要值，并验证握手信息是否一致；如果一致，服务器使用对称加密的密钥加密握手信息发送给浏览器。

6.浏览器解密并验证摘要，若一致，则握手结束。之后数据传送都是用对称加密的密钥进行加密。

 ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/How-HTTPS-Works.png)

**其中第二步使用了 证书 对通信方进行认证**

数字证书认证机构(CA ,Certificate Authority)是客户端与服务器双方都可信赖的第三方认证机构。

服务器运营人员向CA提出公开密钥的申请，CA在判明提出申请者的身份后，会对已申请的公开密钥做数字签名，然后分配这个公开密钥，并将公开密钥放入证书后绑定。

在HTTPS通信时，服务器会把证书发送给客户端。客户端取得公钥后，使用数字签名进行验证，验证通过就可以开始通信。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/2017-06-11-ca.png)

 

**完整性保护**

SSL提供报文摘要功能来进行完整性保护

 

HTTP也提供MD5报文摘要功能，但不安全。例如报文内容被篡改后，同时重新计算MD5的值，通信方是无法意识到发生了篡改。

 

HTTPS的报文摘要功能之所以安全，是因为它结合加密和认证这两个操作。

 

![img](file:////private/var/folders/gw/tm5w3wzx75b28wcz_7klvkxm0000gn/T/com.kingsoft.wpsoffice.mac/wps-zhupeihao/ksohtml/wpszWsxXy.jpg) 

 

总结：非对称加密算法用于在握手过程中能加密生成的密钥；对称加密算法用于对真正传输的数据进行加密；Hash算法用于验证数据的完整性

 

**你访问的网站是如何自动切换到HTTPS的**

https://www.sohu.com/a/136637876_487516

1.一种是原始的302跳转，服务器把所有的HTTP流量跳转到HTTPS，但这样又一个漏洞，就是中间人可能在第一次访问站点的时候就劫持。

2.使用HSTS机制。（HTTP Strict Transport Security）

![img](file:////private/var/folders/gw/tm5w3wzx75b28wcz_7klvkxm0000gn/T/com.kingsoft.wpsoffice.mac/wps-zhupeihao/ksohtml/wps5bQb3j.jpg) 

用户浏览器一旦得到HSTS的信息，下次再访问站点的时候客户端浏览器就会强制使用HTTPS，无论在地址栏里输入什么，都会以HTTPS访问。



 

**什么是对称加密、非对称加密？区别是什么？**

- 对称加密：加密和解密采用相同的密钥。如：DES、RC2、RC4
- 非对称加密：需要两个密钥：公钥和私钥。如果公钥加密，需要用私钥才能解密。如RSA
- 区别：对称加密速度快，通常用于大量数据的加密；非对称加密的安全性更高（不需要传送私钥）

 

**数字签名、报文摘要的原理**

发送者A用私钥进行签名，接受者B用公钥验证签名。

摘要算法：MD5、SHA

 

**HTTPS缺点**

l 需要进行加密和解密过程，速度更慢

l 需要支付证书授权的高额费用

## 2.7 ★★☆ HTTP/1.x 的缺陷，以及 HTTP/2 的特点。

### HTTP/1.x的缺点

HTTP/1.x 实现简单是以牺牲性能为代价的

- HTTP1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多
- 客户端需要使用多个连接才能实现并发和缩短延迟
- 不会压缩请求和响应首部，从而导致不必要的网络流量
- 不支持有效的资源优先级，致使底层TCP连接的利用率低下

 

#### 二进制分帧层

HTTP/2.0将报文分成HEADERS帧和DATA帧，他们都是二进制格式。

通信时只有一个TCP连接，这个连接里有**任意数量的双向数据流**

- 一个数据流都有唯一标识符和可选的优先级信息，用于承载双向信息。
- 消息是与逻辑请求或响应对应的完整的一系列帧
- 帧是最小的通信单位，来自不同数据流的帧可以交错发送，然后根据每个帧头的数据流标识符重新组装

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/af198da1-2480-4043-b07f-a3b91a88b815.png)

#### **服务端推送**

HTTP/2.0在客户端请求一个资源时，会把相关资源一起发送给客户端，客户端就不需要在次发送请求了。

  

#### **首部压缩**

HTTP/1.1的首部带有大量信息，而且每次都要重复发送

HTTP/2.0要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免重复传输

HTTP/2.0使用Huffman编码对首部字段进行压缩

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/_u4E0B_u8F7D.png)

#### 多路复用

连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。

## 2.8 ★★★ HTTP/1.1 和HTTP1/.0的区别。

- HTTP1.1默认是长连接的，一个TCP连接可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。HTTP1.0是短连接
- HTTP1.1支持流水线，支持同时打开多个TCP连接
- HTTP1.1新增24个错误状态码
- 支持分块传输编码
- 新增缓存处理指令 max-age

## 2.9 ★★☆ HTTP 与 FTP 的比较。

https://blog.csdn.net/only_musm/article/details/78983364

**相同点：**

1.都是应用层协议

2.都运行在TCP上

 

**不同点：**

1.HTTP是超文本传输协议，是面向网页的；FTP是文件传输协议，是面向文件的

2.HTTP协议默认端口：80；FTP：21端口发送控制连接

3.FTP控制信息是带外传送，而HTTP控制信息是带内传送的

4.FTP服务器必须在整个会话期间保留用户的状态信息，而HTTP是无状态的。

FTP服务器必须把特定的用户账户与控制连接信息联系起来，随着用户在远程目录树上移动，服务器必须追踪用户在远程目录树上的当前位置。对每个活动的用户会话状态进行追踪，可以对FTP会话总数进行限制。

5.FTP的控制连接是持久连接，数据连接是非持久连接；而HTTP既可以是非持久连接，也可以是持久连接，默认是持久连接，FTP有两种工作方式：

两种方式的控制链路连接过程是一样的，都是客户端向服务器的FTP端口（21）发送连接请求，服务器接受连接后建立控制连接链路。

根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：

- 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/03f47940-3843-4b51-9e42-5dcaff44858b.jpg)

- 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。

如果还需要传送文件，需要在打开一个数据连接。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/be5c2c61-86d2-4dba-a289-b48ea23219de.jpg)

## 2.10 ★★ ★ 浏览器输入www.baidu.com 后执行的全部过程

#### 1.DNS域名解析

1）主机通过浏览器生成一个TCP套接字，套接字向HTTP服务器发送HTTP请求，为了生成这个套接字，主机需要知道网站域名的IP地址。主机生成一个DNS查询报文，端口号是53，这个DNS查询报文放入IP数据报中（目的IP地址是DNS服务器），然后将该IP数据报放入一个以太网帧中发送到网关路由器

#### 2.ARP协议查询网关路由器MAC地址

2）看看主机的ARP缓存中是否有网关路由器的MAC地址，有的话直接发送，如果没有的话需要使用ARP协议。主机生成一个ARP查询报文（目的IP地址是网关路由器的IP地址），将该ARP查询报文放入一个具有广博目的地址的以太网帧中，并向交换机发送该帧，交换机会把这个帧发送给所有设备，包括网关路由器。网关路由器接收到该帧以后向上解析，发现IP地址匹配，就发送一个ARP应答报文，包含自己的MAC地址，发回给主机。

#### 3.继续DNS域名解析

3）然后就可以向网关路由器发送DNS查询报文了，网关路由器获得该IP数据报以后查询自己的路由表，到达DNS服务器之后去其数据库中查找带解析的域名，然后发送DNS应答报文，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。

#### 4.发送HTTP请求

客户端浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径。客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层。

2）在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。

3）客户端的网络层不用关心应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，不作过多的描述，无非就是通过查找路由表决定通过那个路径到达服务器。

4）客户端的链路层，包通过链路层发送到路由器，通过ARP协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。

**注意：这里主要介绍的是在各个网络层的走向，实际HTTP在生成TCP套接字之前还需要与HTTP服务器进行三次握手**

# 3 Socket

## 3.1 ★★☆ 五种 IO 模型的特点以及比较。

相关代码参考：

https://github.com/caijinlin/learning-pratice/tree/master/linux/io

可以参考另一篇文章

https://mp.weixin.qq.com/s?__biz=MzUxMzQ0Njc1NQ==&mid=2247486581&idx=1&sn=390f6c6b7dd647e334b34f8f51008cab&chksm=f9544a79ce23c36fcd45d9de55e3652d14ad3bb4d45460a7ece5b916e8b46da79ad37c5e2cbe&mpshare=1&scene=23&srcid=07163oS95nXAnqTIEJJ58rVS&sharer_sharetime=1594901798946&sharer_shareid=0b5259c676795139071f4f7ade041a11%23rd



输入操作包括两个阶段：

1.等待数据准备好（等待数据从网络到达）

2.从内核向进程复制数据（从内核缓冲区复制到应用进程缓冲区）

 

Unix五种I/O模型

- 同步阻塞式I/O

应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区才返回。

在阻塞过程中，其他应用进程还可以执行，不消耗CPU时间，这种模型的CPU利用率会比较高。

**recvfrom()用于接受Socket传来的数据，并复制到应用进程的缓冲区**

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492928416812_4.png)

如果服务端采用单线程，那么这个进程被阻塞后，进程后续的请求都无法被执行，无法处理并发。

如果服务端采用多线程，每次来一个请求都可以开启一个线程来处理，这样可以处理并发， **但是大量线程占用很大的内存，并且线程的切换会带来很大的开销。10000个线程真正发生读写事件的线程数不会超过20%，每次accept都开一个线程也是一种资源浪费**

 

- 同步非阻塞式I/O

应用进程执行一个系统调用后，内核返回一个错误码。应用进程可以继续执行，但是需要不断执行系统调用来获知I/O是否完成，称为轮询。服务器端当accept一个请求后，加入fds集合，每次轮询一遍fds集合recv(非阻塞)数据，没有数据则立即返回错误，`每次轮询所有fd（包括没有发生读写事件的fd）会很浪费cpu`

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492929000361_5.png) 

- I/O复用（select和poll）

使用select或者poll等待数据，并且可以等待多个套接字的任何一个变为可读。这个过程会被阻塞，当某个套接字可读时返回，在使用recvfrom把数据从内核复制到进程中。

它可以让单个进程具有处理多个I/O事件的能力。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492929444818_6.png)

- 信号驱动式I/O(SIGIO)

应用进程使用sigaction系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段进程是非阻塞的。内核在数据到达时向应用进程发送SIGIO信号，应用进程收到后调用recvfrom将数据从内核复制到应用进程。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492929553651_7.png) 

- 异步I/O(AIIO)

应用进程执行aio_read系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核在所有操作完成后向应用进程发送信号。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492930243286_8.png) 

**五种I/O的比较**

- 同步I/O：将数据从内核缓冲区复制到应用进程缓冲区时会阻塞（第二阶段）
- 异步I/O；第二阶段不会阻塞

 

同步I/O包括阻塞式I/O、非阻塞式I/O、I/O复用和信号驱动I/O，他们之间主要区别在第一阶段，

非阻塞I/O、信号驱动I/O和异步I/O第一阶段不会阻塞。

 

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492928105791_3.png)





#### 有哪些常见的IO模型？

- 同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够；
- 同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源；
- IO多路复用
- 异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。



## 3.2 ★★★ select、poll、epoll 的原理、比较、以及使用场景；epoll 的水平触发与边缘触发。

IO多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。

实现原理：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置timeout），函数就会返回，然后该进程可以进行相应的读/写操作。

<details>
<summary>select/poll/epoll三者的区别？</summary>


- ```select```：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间

  （缺点1：每次都要复制，**开销大**），由内核根据就绪状态修改该集合的内容。

  （缺点2）**集合大小有限制**，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符

  （缺点3：**轮询的方式效率较低**），当文件描述符的数量增加时，效率会线性下降；

- ```poll```：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制；

- ```epoll```：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。

  （缺点：只能工作在Linux下）

#### select/poll/epoll的区别



|            | select                      | poll             | epoll                                             |
| ---------- | --------------------------- | ---------------- | ------------------------------------------------- |
| 数据结构   | bitmap                      | 数组             | 红黑树                                            |
| 最大连接数 | 1024(32位机)/2048（64位机） | 无上限           | 无上限                                            |
| fd拷贝     | 每次调用select拷贝          | 每次调用poll拷贝 | fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 |
| 工作效率   | 轮询：O(n)                  | 轮询：O(n)       | 回调：O(1)                                        |



#### 什么时候使用select/poll，什么时候使用epoll？

Epoll:当连接数较多并且有很多的不活跃连接时.但是当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能可能低于其它两者。nginx/redis都使用epoll

Select: select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。

Poll:



#### 什么是文件描述符？

文件描述符在形式上是一个非负整数。实际上，它是一个索引值，用以标明每一个被进程所打开的文件和socket。第一个打开的文件是0，第二个是1，依此类推。一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。

**内核通过文件描述符来访问文件。文件描述符指向一个文件。**



#### 什么是水平触发？什么是边缘触发？

https://blog.csdn.net/lihao21/article/details/67631516

- 水平触发（LT，Level Trigger）模式下，只要还有FD就绪,每次调用epoll_wait()都会通知用户进程去处理对应的FD。是默认的一种模式，支持阻塞和非阻塞；

- 边缘触发（ET，Edge Trigger）模式下，当FD从未就绪变为就绪时通知一次，之后不会再通知，直到又有FD从未就绪变为就绪（缓冲区从不可读/写变为可读/写），所以每次read一个fd的时候要把他的buffer读完，仅支持非阻塞。

  

  **水平触发**

  1. 对于读操作
  只要缓冲内容不为空，LT模式返回读就绪。

  2. 对于写操作
  只要缓冲区还不满，LT模式会返回写就绪。

  **边缘触发**

  1. 对于读操作
     
  
    （1）当缓冲区由不可读变为可读的时候，即缓冲区由空变为不空的时候。
  
  （2）当有新数据到达时，即缓冲区中的待读数据变多的时候。
  
  （3）当缓冲区有数据可读，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLIN事件时。
  
  2. 对于写操作
      （1）当缓冲区由不可写变为可写时。
  
  （2）当有旧数据被发送走，即缓冲区中的内容变少的时候。
  
  （3）当缓冲区有空间可写，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLOUT事件时。
  
**区别：**边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。
  

  
  **为什么边缘触发一定要用非阻塞（non-block）IO：**因为边缘触发当描述符就绪时就会立即处理，避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态（如果短时间内很多描述符都就绪了，如果采用阻塞IO的话就会）。



## 3.3 ★★★ Reactor模型和Proactor模型

https://www.jianshu.com/p/5fe6c59e5c00

### Reactor

PPC和TPC模式无法支持高并发，每来一个连接就创建一个进程或线程，连接结束就销毁，浪费太大。可以实现资源的复用，创建线程池，一个线程处理多个连接业务。

引入**资源池**的处理方式后，会引出一个新的问题：进程如何才能高效地处理多个连接的业务？当**一个连接一个进程**时，进程可以采用“**read -> 业务处理 -> write”的处理流程**，如果当前连接没有数据可以读，则进程就**阻塞在 read 操作上**。这种阻塞的方式在一个连接一个进程的场景下没有问题，但如果一个进程处理多个连接，进程阻塞在某个连接的 read 操作上，此时即使其他连接有数据可读，进程也无法去处理，很显然这样是**无法做到高性能**的。

最简单的方式就是将 **read操作改成非阻塞，然后进程不断轮询多个连接**，但是**轮询是要消耗 CPU** 的；其次，如果一个进程处理几千上万的连接，则**轮询的效率是很低**的。

为了能够更好地解决上述问题，很容易可以想到，只有当**连接上有数据**的时候进**程才去处理**，这就是 **I/O 多路复用技术**的来源。

当某条连接有新的数据可以处理时，操作系统通知进程，进程从阻塞状态返回，开始进行业务处理。简单点说就是IO多路复用统一监听事件、收到事件后分配给某个进程来处理。核心组件：Reactor和处理资源池（**进程池或线程池**）实际上Reactor模式可以灵活多变，根据Reactor和资源池中线程的数量可以分为：

**单 Reactor 单进程 / 线程。**

**单 Reactor 多线程。**

**多 Reactor 多进程 / 线程。**



##### 单 Reactor 单进程 / 线程。

![img](https://upload-images.jianshu.io/upload_images/9930763-b6070528a89c1fef.png?imageMogr2/auto-orient/strip|imageView2/2/w/644/format/webp)

1）Reactor 对象通过 select 监控连接事件，收到事件后通过 **dispatch 进行分发**。

2）如果是**连接建立的事件**，则由 Acceptor 处理，**Acceptor 通过 accept 接受连接，并创建一个 Handler 来处理连接后续的各种事件**。

如果不是连接建立事件，则 **Reactor** 会**调用**连接对应的 **Handler**（第 2 步中创建的 Handler）来进行响应。

3）Handler 会完成 **read**-> 业务处理 ->send 的完整业务流程。

Handler 在处理某个连接上的业务时，整个进程无法处理其他连接的事件，很容易导致性能瓶颈。

因此，单 Reactor 单进程的方案在实践中应用场景不多，**只适用于业务处理非常快速的场景**，目前比较著名的开源软件中使用单 **Reactor 单进程的是 Redis**。



##### 单 Reactor 多线程。

![img](https://upload-images.jianshu.io/upload_images/9930763-a57c37f88f4c0f7d.png?imageMogr2/auto-orient/strip|imageView2/2/w/746/format/webp)

与单线程不同的地方在于，Handler只负责的响应事件，不负责业务处理。业务处理交给子线程的Processor来处理。

 Reator 多线程方案能够充分利用**多核多 CPU** 的处理能力。但是**Reactor** 承担所有事件的**监听和响应**，只在主线程中运行，瞬间**高并发时会成为性能瓶颈**；多线程数据共享和访问比较复杂。



##### 多 Reactor 多进程 / 线程。

![img](https://upload-images.jianshu.io/upload_images/9930763-abc02d3358b71c07.png?imageMogr2/auto-orient/strip|imageView2/2/w/738/format/webp)

父进程中 mainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 接收，将新的连接分配给某个子进程。

子进程的 subReactor 将 mainReactor 分配的连接加入连接队列进行监听，并创建一个 Handler 用于处理连接的各种事件。

当有新的事件发生时，subReactor 会调用连接对应的 Handler（即第 2 步中创建的 Handler）来进行响应。

Handler 完成 read→业务处理→send 的完整业务流程。

父进程和子进程的职责非常明确，**父进程只负责接收新连接，子进程负责完成后续的业务处理**。

父进程和子进程的**交互很简单**，父进程只需要把新连接传给子进程，子进程无须返回数据。

子进程之间是互相独立的，无须同步共享之类的处理（这里仅限于网络模型相关的 select、read、send 等无须同步共享，“业务处理”还是有可能需要同步共享的）。

目前著名的开源系统 **Nginx** 采用的是**多 Reactor 多进程**，采用多 Reactor 多线程的实现有 **Memcache 和 Netty**。



### Proactor

异步IO，有新的连接，操作系统将数据读写到应用传递进来的缓冲区，然后通知用户进程进行处理

![img](https://upload-images.jianshu.io/upload_images/9930763-2062a7ee9b51e483.png?imageMogr2/auto-orient/strip|imageView2/2/w/673/format/webp)

Proactor Initiator 负责创建 Proactor 和 Handler，并将 Proactor 和 Handler 都通过 Asynchronous Operation Processor 注册到内核。

Asynchronous Operation Processor 负责处理注册请求，并完成 I/O 操作。完成 I/O 操作后通知 Proactor。

Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理。

Handler 完成业务处理，Handler 也可以注册新的 Handler 到内核进程。



